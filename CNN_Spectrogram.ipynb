{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test CNN on spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9ce7a6e8d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize data into something useable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_kfold(k_fold=1):\n",
    "    features_og = np.load('features_nonsliding_ch.npy')\n",
    "    targets_og = np.load('targets_nonsliding_ch.npy')\n",
    "    print(sum(targets_og),targets_og.shape)\n",
    "\n",
    "    # Split data into train and test\n",
    "    split = np.arange(len(targets_og))\n",
    "    np.random.shuffle(split)\n",
    "    features_og = features_og[split]\n",
    "    targets_og = targets_og[split]\n",
    "    features_og_0 = features_og[np.where(targets_og==0)[0]]\n",
    "    features_og_1 = features_og[np.where(targets_og==1)[0]]\n",
    "    targets_og_0 = targets_og[np.where(targets_og==0)[0]]\n",
    "    targets_og_1 = targets_og[np.where(targets_og==1)[0]]\n",
    "    N_0 = len(targets_og_0)\n",
    "    N_1 = len(targets_og_1)\n",
    "    \n",
    "    features_og_train = np.vstack([features_og_0,features_og_1])\n",
    "    targets_og_train = np.vstack([targets_og_0,targets_og_1])\n",
    "    sample_list = []\n",
    "    for i in range(k_fold):\n",
    "        if (i+1)==k_fold:\n",
    "            temp1 = np.arange(i*N_0//k_fold,N_0, dtype=np.int64)\n",
    "            temp2 = np.arange(i*N_1//k_fold,N_1, dtype=np.int64)+N_0\n",
    "        else:\n",
    "            temp1 = np.arange(i*N_0//k_fold,(i+1)*N_0//k_fold, dtype=np.int64)\n",
    "            temp2 = np.arange(i*N_1//k_fold,(i+1)*N_1//k_fold, dtype=np.int64)+N_0\n",
    "        temp2 = np.repeat(temp2,250)\n",
    "        sample_list.append(np.hstack([temp1,temp2]))\n",
    "    \n",
    "    train_sampler_list = []\n",
    "    test_sampler_list = []\n",
    "    for i in range(k_fold):\n",
    "        temp = np.where(np.arange(len(sample_list), dtype=np.int64) != i)[0]\n",
    "        train =  np.hstack([sample_list[x] for x in temp])\n",
    "        test = sample_list[i]\n",
    "        train_sampler_list.append(SubsetRandomSampler(train))\n",
    "        test_sampler_list.append(SubsetRandomSampler(test))\n",
    "        \n",
    "    # Convert data to tensor dataset\n",
    "    features = torch.from_numpy(features_og_train).float()\n",
    "    targets = torch.from_numpy(targets_og_train).long()\n",
    "    targets = torch.squeeze(targets)\n",
    "    train = data_utils.TensorDataset(features, targets)\n",
    "    \n",
    "    return train_sampler_list, test_sampler_list, train\n",
    "    \n",
    "def split_train_test(train_percent, k_fold=0):\n",
    "    features_og = np.load('features_nonsliding_ch.npy')\n",
    "    targets_og = np.load('targets_nonsliding_ch.npy')\n",
    "    print(sum(targets_og),targets_og.shape)\n",
    "\n",
    "    # Split data into train and test\n",
    "    split = np.arange(len(targets_og))\n",
    "    np.random.shuffle(split)\n",
    "    features_og = features_og[split]\n",
    "    targets_og = targets_og[split]\n",
    "    features_og_0 = features_og[np.where(targets_og==0)[0]]\n",
    "    features_og_1 = features_og[np.where(targets_og==1)[0]]\n",
    "    targets_og_0 = targets_og[np.where(targets_og==0)[0]]\n",
    "    targets_og_1 = targets_og[np.where(targets_og==1)[0]]\n",
    "    N_0 = len(targets_og_0)\n",
    "    N_1 = len(targets_og_1)\n",
    "    \n",
    "    features_og_train = np.vstack([features_og_0[:int(train_percent*N_0)],features_og_1[:int(train_percent*N_1)]])\n",
    "    targets_og_train = np.vstack([targets_og_0[:int(train_percent*N_0)],targets_og_1[:int(train_percent*N_1)]])\n",
    "    features_og_test = np.vstack([features_og_0[int(train_percent*N_0):],features_og_1[int(train_percent*N_1):]])\n",
    "    targets_og_test = np.vstack([targets_og_0[int(train_percent*N_0):],targets_og_1[int(train_percent*N_1):]])\n",
    "    print(sum(targets_og_train), sum(targets_og_test))\n",
    "    \n",
    "\n",
    "    # Balance dataset\n",
    "    # ~1/4000 seizure events\n",
    "    idx = np.hstack([np.where(targets_og_train == 0)[0], \n",
    "                     np.repeat(np.where(targets_og_train == 1)[0], 100)]) # Oversample\n",
    "    features = features_og_train[idx]\n",
    "    targets = targets_og_train[idx]\n",
    "\n",
    "    # Convert data to tensor dataset\n",
    "    features = torch.from_numpy(features).float()\n",
    "    targets = torch.from_numpy(targets).long()\n",
    "    targets = torch.squeeze(targets)\n",
    "    train = data_utils.TensorDataset(features, targets)\n",
    "\n",
    "    N = features.size()[0]\n",
    "    sample_list = np.arange(N, dtype=np.int64)\n",
    "    np.random.shuffle(sample_list)\n",
    "    percent_train = 1.0\n",
    "\n",
    "    #Training\n",
    "    n_training_samples = int(N*percent_train)\n",
    "    train_sampler = SubsetRandomSampler(sample_list[:n_training_samples])\n",
    "\n",
    "    #Validation\n",
    "    val_sampler = SubsetRandomSampler(sample_list[:n_training_samples])\n",
    "\n",
    "    #Test data\n",
    "    features = torch.from_numpy(features_og_test).float()\n",
    "    targets = torch.from_numpy(targets_og_test).long()\n",
    "    targets = torch.squeeze(targets)\n",
    "    test = data_utils.TensorDataset(features, targets)\n",
    "    return train, test, train_sampler, val_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(torch.nn.Module):\n",
    "    \n",
    "    #Our batch shape for input x is (3, 32, 32)\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        #Input channels = 1, output channels = 18\n",
    "        self.conv1 = torch.nn.Conv2d(23, 18, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        #4608 input features, 64 output features (see sizing flow below)\n",
    "        self.fc1 = torch.nn.Linear(18 * 16 * 16, 64)\n",
    "        \n",
    "        #64 input features, 10 output features for our 10 defined classes\n",
    "        self.fc2 = torch.nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #Computes the activation of the first convolution\n",
    "        #Size changes from (3, 32, 32) to (18, 32, 32)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        #Size changes from (18, 32, 32) to (18, 16, 16)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        #Reshape data to input to the input layer of the neural net\n",
    "        #Size changes from (18, 16, 16) to (1, 4608)\n",
    "        #Recall that the -1 infers this dimension from the other given dimension\n",
    "        x = x.view(-1, 18 * 16 *16)\n",
    "        \n",
    "        #Computes the activation of the first fully connected layer\n",
    "        #Size changes from (1, 4608) to (1, 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        #Computes the second fully connected layer (activation applied later)\n",
    "        #Size changes from (1, 64) to (1, 10)\n",
    "        x = self.fc2(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoader takes in a dataset and a sampler for loading (num_workers deals with system level memory) \n",
    "def get_train_loader(batch_size, train_sampler):\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size,\n",
    "                                           sampler=train_sampler, num_workers=2)\n",
    "    return(train_loader)\n",
    "\n",
    "#Test and validation loaders have constant batch sizes, so we can define them directly\n",
    "\n",
    "def trainNet(net, train_sampler, batch_size, n_epochs, learning_rate):\n",
    "    \n",
    "    #Print all of the hyperparameters of the training iteration:\n",
    "    print(\"===== HYPERPARAMETERS =====\")\n",
    "    print(\"batch_size=\", batch_size)\n",
    "    print(\"epochs=\", n_epochs)\n",
    "    print(\"learning_rate=\", learning_rate)\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    #Get training data\n",
    "    train_loader = get_train_loader(batch_size, train_sampler)\n",
    "    n_batches = len(train_loader)\n",
    "    \n",
    "    #Create our loss and optimizer functions\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    #Time for printing\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    #Loop for n_epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        print_every = n_batches // 10\n",
    "        start_time = time.time()\n",
    "        total_train_loss = 0.0\n",
    "        \n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            \n",
    "            #Get inputs\n",
    "            inputs, labels = data\n",
    "            \n",
    "            #Wrap them in a Variable object\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            \n",
    "            #Set the parameter gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #Forward pass, backward pass, optimize\n",
    "            outputs = net(inputs)\n",
    "            loss_size = loss(outputs, labels)\n",
    "            loss_size.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Print statistics\n",
    "            running_loss += loss_size.data[0]\n",
    "            total_train_loss += loss_size.data[0]\n",
    "            \n",
    "            #Print every 10th batch of an epoch\n",
    "            if (i + 1) % (print_every + 1) == 0:\n",
    "                print(\"Epoch {}, {:d}% \\t train_loss: {:.6f} took: {:.2f}s\".format(\n",
    "                        epoch+1, int(100 * (i+1) / n_batches), running_loss / print_every, time.time() - start_time))\n",
    "                #Reset running loss and time\n",
    "                running_loss = 0.0\n",
    "                start_time = time.time()\n",
    "            \n",
    "        #At the end of the epoch, do a pass on the validation set\n",
    "        total_val_loss = 0\n",
    "        for inputs, labels in val_loader:            \n",
    "            #Wrap tensors in Variables\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            \n",
    "            #Forward pass\n",
    "            val_outputs = net(inputs)\n",
    "            val_loss_size = loss(val_outputs, labels)\n",
    "            total_val_loss += val_loss_size.data[0]\n",
    "            \n",
    "        print(\"Validation loss = {:.2f}\".format(total_val_loss / max(1,len(val_loader))))\n",
    "        \n",
    "\n",
    "        print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))\n",
    "        \n",
    "def calculate_cm(test_sampler):\n",
    "    test_loader = torch.utils.data.DataLoader(train, sampler=test_sampler, batch_size=2)\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data          \n",
    "            outputs = CNN(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            for x,y in zip(predicted, labels):\n",
    "                y_true.append(int(y.numpy()))\n",
    "                y_pred.append(int(x.numpy()))\n",
    "    return confusion_matrix(np.array(y_true), np.array(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 4\n",
      "epochs= 20\n",
      "learning_rate= 1e-07\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Christian/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/Christian/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:57: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, 10% \t train_loss: 2.583366 took: 1.68s\n",
      "Epoch 1, 20% \t train_loss: 1.967699 took: 1.16s\n",
      "Epoch 1, 30% \t train_loss: 1.458107 took: 1.18s\n",
      "Epoch 1, 40% \t train_loss: 1.249286 took: 1.29s\n",
      "Epoch 1, 50% \t train_loss: 1.024508 took: 1.16s\n",
      "Epoch 1, 60% \t train_loss: 0.951950 took: 1.19s\n",
      "Epoch 1, 70% \t train_loss: 0.825036 took: 1.14s\n",
      "Epoch 1, 80% \t train_loss: 0.809808 took: 1.23s\n",
      "Epoch 1, 90% \t train_loss: 0.701772 took: 1.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Christian/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:76: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss = 0.63\n",
      "Epoch 2, 10% \t train_loss: 0.594906 took: 1.77s\n",
      "Epoch 2, 20% \t train_loss: 0.599846 took: 1.16s\n",
      "Epoch 2, 30% \t train_loss: 0.531406 took: 1.39s\n",
      "Epoch 2, 40% \t train_loss: 0.535186 took: 1.17s\n",
      "Epoch 2, 50% \t train_loss: 0.511298 took: 1.21s\n",
      "Epoch 2, 60% \t train_loss: 0.462963 took: 1.21s\n",
      "Epoch 2, 70% \t train_loss: 0.439777 took: 1.20s\n",
      "Epoch 2, 80% \t train_loss: 0.380659 took: 1.18s\n",
      "Epoch 2, 90% \t train_loss: 0.389825 took: 1.24s\n",
      "Validation loss = 0.37\n",
      "Epoch 3, 10% \t train_loss: 0.362626 took: 1.73s\n",
      "Epoch 3, 20% \t train_loss: 0.326635 took: 1.37s\n",
      "Epoch 3, 30% \t train_loss: 0.323807 took: 1.18s\n",
      "Epoch 3, 40% \t train_loss: 0.303603 took: 1.33s\n",
      "Epoch 3, 50% \t train_loss: 0.317406 took: 1.17s\n",
      "Epoch 3, 60% \t train_loss: 0.300134 took: 1.19s\n",
      "Epoch 3, 70% \t train_loss: 0.258814 took: 1.27s\n",
      "Epoch 3, 80% \t train_loss: 0.262742 took: 1.30s\n",
      "Epoch 3, 90% \t train_loss: 0.254640 took: 1.21s\n",
      "Validation loss = 0.23\n",
      "Epoch 4, 10% \t train_loss: 0.236902 took: 1.84s\n",
      "Epoch 4, 20% \t train_loss: 0.207751 took: 1.14s\n",
      "Epoch 4, 30% \t train_loss: 0.195732 took: 1.24s\n",
      "Epoch 4, 40% \t train_loss: 0.206894 took: 1.23s\n",
      "Epoch 4, 50% \t train_loss: 0.190862 took: 1.19s\n",
      "Epoch 4, 60% \t train_loss: 0.183493 took: 1.22s\n",
      "Epoch 4, 70% \t train_loss: 0.173205 took: 1.21s\n",
      "Epoch 4, 80% \t train_loss: 0.165101 took: 1.16s\n",
      "Epoch 4, 90% \t train_loss: 0.164744 took: 1.31s\n",
      "Validation loss = 0.15\n",
      "Epoch 5, 10% \t train_loss: 0.153121 took: 1.77s\n",
      "Epoch 5, 20% \t train_loss: 0.147069 took: 1.24s\n",
      "Epoch 5, 30% \t train_loss: 0.130890 took: 1.19s\n",
      "Epoch 5, 40% \t train_loss: 0.141928 took: 1.17s\n",
      "Epoch 5, 50% \t train_loss: 0.127699 took: 1.22s\n",
      "Epoch 5, 60% \t train_loss: 0.130278 took: 1.15s\n",
      "Epoch 5, 70% \t train_loss: 0.119105 took: 1.21s\n",
      "Epoch 5, 80% \t train_loss: 0.113816 took: 1.20s\n",
      "Epoch 5, 90% \t train_loss: 0.104380 took: 1.25s\n",
      "Validation loss = 0.11\n",
      "Epoch 6, 10% \t train_loss: 0.106332 took: 1.88s\n",
      "Epoch 6, 20% \t train_loss: 0.100688 took: 1.23s\n",
      "Epoch 6, 30% \t train_loss: 0.099748 took: 1.21s\n",
      "Epoch 6, 40% \t train_loss: 0.094200 took: 1.26s\n",
      "Epoch 6, 50% \t train_loss: 0.097481 took: 1.22s\n",
      "Epoch 6, 60% \t train_loss: 0.089355 took: 1.29s\n",
      "Epoch 6, 70% \t train_loss: 0.081493 took: 1.29s\n",
      "Epoch 6, 80% \t train_loss: 0.081084 took: 1.53s\n",
      "Epoch 6, 90% \t train_loss: 0.073743 took: 1.20s\n",
      "Validation loss = 0.08\n",
      "Epoch 7, 10% \t train_loss: 0.069279 took: 1.84s\n",
      "Epoch 7, 20% \t train_loss: 0.075833 took: 1.17s\n",
      "Epoch 7, 30% \t train_loss: 0.073068 took: 1.20s\n",
      "Epoch 7, 40% \t train_loss: 0.062502 took: 1.22s\n",
      "Epoch 7, 50% \t train_loss: 0.068309 took: 1.23s\n",
      "Epoch 7, 60% \t train_loss: 0.071620 took: 1.21s\n",
      "Epoch 7, 70% \t train_loss: 0.058871 took: 1.40s\n",
      "Epoch 7, 80% \t train_loss: 0.057762 took: 1.19s\n",
      "Epoch 7, 90% \t train_loss: 0.059235 took: 1.37s\n",
      "Validation loss = 0.06\n",
      "Epoch 8, 10% \t train_loss: 0.056437 took: 1.86s\n",
      "Epoch 8, 20% \t train_loss: 0.052368 took: 1.24s\n",
      "Epoch 8, 30% \t train_loss: 0.052442 took: 1.16s\n",
      "Epoch 8, 40% \t train_loss: 0.049000 took: 1.28s\n",
      "Epoch 8, 50% \t train_loss: 0.044568 took: 1.23s\n",
      "Epoch 8, 60% \t train_loss: 0.048906 took: 1.35s\n",
      "Epoch 8, 70% \t train_loss: 0.050257 took: 1.24s\n",
      "Epoch 8, 80% \t train_loss: 0.046007 took: 1.30s\n",
      "Epoch 8, 90% \t train_loss: 0.042441 took: 1.21s\n",
      "Validation loss = 0.04\n",
      "Epoch 9, 10% \t train_loss: 0.041483 took: 1.79s\n",
      "Epoch 9, 20% \t train_loss: 0.040842 took: 1.19s\n",
      "Epoch 9, 30% \t train_loss: 0.041501 took: 1.25s\n",
      "Epoch 9, 40% \t train_loss: 0.039356 took: 1.54s\n",
      "Epoch 9, 50% \t train_loss: 0.039502 took: 1.24s\n",
      "Epoch 9, 60% \t train_loss: 0.036986 took: 1.27s\n",
      "Epoch 9, 70% \t train_loss: 0.029119 took: 1.22s\n",
      "Epoch 9, 80% \t train_loss: 0.030200 took: 1.20s\n",
      "Epoch 9, 90% \t train_loss: 0.036338 took: 1.24s\n",
      "Validation loss = 0.03\n",
      "Epoch 10, 10% \t train_loss: 0.029472 took: 1.82s\n",
      "Epoch 10, 20% \t train_loss: 0.032679 took: 1.27s\n",
      "Epoch 10, 30% \t train_loss: 0.031274 took: 1.38s\n",
      "Epoch 10, 40% \t train_loss: 0.027843 took: 1.16s\n",
      "Epoch 10, 50% \t train_loss: 0.028119 took: 1.22s\n",
      "Epoch 10, 60% \t train_loss: 0.025337 took: 1.21s\n",
      "Epoch 10, 70% \t train_loss: 0.024056 took: 1.17s\n",
      "Epoch 10, 80% \t train_loss: 0.031149 took: 1.24s\n",
      "Epoch 10, 90% \t train_loss: 0.027894 took: 1.24s\n",
      "Validation loss = 0.02\n",
      "Epoch 11, 10% \t train_loss: 0.028357 took: 1.86s\n",
      "Epoch 11, 20% \t train_loss: 0.022247 took: 1.33s\n",
      "Epoch 11, 30% \t train_loss: 0.023028 took: 1.18s\n",
      "Epoch 11, 40% \t train_loss: 0.024196 took: 1.26s\n",
      "Epoch 11, 50% \t train_loss: 0.021805 took: 1.26s\n",
      "Epoch 11, 60% \t train_loss: 0.023337 took: 1.19s\n",
      "Epoch 11, 70% \t train_loss: 0.022901 took: 1.20s\n",
      "Epoch 11, 80% \t train_loss: 0.019352 took: 1.19s\n",
      "Epoch 11, 90% \t train_loss: 0.020438 took: 1.22s\n",
      "Validation loss = 0.02\n",
      "Epoch 12, 10% \t train_loss: 0.022203 took: 1.87s\n",
      "Epoch 12, 20% \t train_loss: 0.018673 took: 1.20s\n",
      "Epoch 12, 30% \t train_loss: 0.016848 took: 1.21s\n",
      "Epoch 12, 40% \t train_loss: 0.024832 took: 1.18s\n",
      "Epoch 12, 50% \t train_loss: 0.016264 took: 1.25s\n",
      "Epoch 12, 60% \t train_loss: 0.017310 took: 1.21s\n",
      "Epoch 12, 70% \t train_loss: 0.020573 took: 1.23s\n",
      "Epoch 12, 80% \t train_loss: 0.017625 took: 1.24s\n",
      "Epoch 12, 90% \t train_loss: 0.015081 took: 1.31s\n",
      "Validation loss = 0.02\n",
      "Epoch 13, 10% \t train_loss: 0.015290 took: 1.84s\n",
      "Epoch 13, 20% \t train_loss: 0.012431 took: 1.27s\n",
      "Epoch 13, 30% \t train_loss: 0.014595 took: 1.22s\n",
      "Epoch 13, 40% \t train_loss: 0.016578 took: 1.66s\n",
      "Epoch 13, 50% \t train_loss: 0.017841 took: 1.44s\n",
      "Epoch 13, 60% \t train_loss: 0.017156 took: 1.38s\n",
      "Epoch 13, 70% \t train_loss: 0.014740 took: 1.15s\n",
      "Epoch 13, 80% \t train_loss: 0.017419 took: 1.23s\n",
      "Epoch 13, 90% \t train_loss: 0.012362 took: 1.24s\n",
      "Validation loss = 0.01\n",
      "Epoch 14, 10% \t train_loss: 0.012291 took: 1.84s\n",
      "Epoch 14, 20% \t train_loss: 0.012519 took: 1.28s\n",
      "Epoch 14, 30% \t train_loss: 0.015231 took: 1.27s\n",
      "Epoch 14, 40% \t train_loss: 0.012213 took: 1.22s\n",
      "Epoch 14, 50% \t train_loss: 0.012857 took: 1.22s\n",
      "Epoch 14, 60% \t train_loss: 0.010680 took: 1.17s\n",
      "Epoch 14, 70% \t train_loss: 0.010759 took: 1.20s\n",
      "Epoch 14, 80% \t train_loss: 0.018781 took: 1.17s\n",
      "Epoch 14, 90% \t train_loss: 0.013096 took: 1.28s\n",
      "Validation loss = 0.01\n",
      "Epoch 15, 10% \t train_loss: 0.012500 took: 1.96s\n",
      "Epoch 15, 20% \t train_loss: 0.011732 took: 1.14s\n",
      "Epoch 15, 30% \t train_loss: 0.010180 took: 1.22s\n",
      "Epoch 15, 40% \t train_loss: 0.010766 took: 1.15s\n",
      "Epoch 15, 50% \t train_loss: 0.008794 took: 1.21s\n",
      "Epoch 15, 60% \t train_loss: 0.012770 took: 1.19s\n",
      "Epoch 15, 70% \t train_loss: 0.011361 took: 1.19s\n",
      "Epoch 15, 80% \t train_loss: 0.013226 took: 1.19s\n",
      "Epoch 15, 90% \t train_loss: 0.010352 took: 1.18s\n",
      "Validation loss = 0.01\n",
      "Epoch 16, 10% \t train_loss: 0.008271 took: 1.83s\n",
      "Epoch 16, 20% \t train_loss: 0.010049 took: 1.21s\n",
      "Epoch 16, 30% \t train_loss: 0.011010 took: 1.19s\n",
      "Epoch 16, 40% \t train_loss: 0.009727 took: 1.23s\n",
      "Epoch 16, 50% \t train_loss: 0.008836 took: 1.16s\n",
      "Epoch 16, 60% \t train_loss: 0.009823 took: 1.22s\n",
      "Epoch 16, 70% \t train_loss: 0.010470 took: 1.52s\n",
      "Epoch 16, 80% \t train_loss: 0.010857 took: 1.21s\n",
      "Epoch 16, 90% \t train_loss: 0.010409 took: 1.29s\n",
      "Validation loss = 0.01\n",
      "Epoch 17, 10% \t train_loss: 0.012712 took: 1.77s\n",
      "Epoch 17, 20% \t train_loss: 0.008731 took: 1.18s\n",
      "Epoch 17, 30% \t train_loss: 0.006766 took: 1.19s\n",
      "Epoch 17, 40% \t train_loss: 0.007542 took: 1.15s\n",
      "Epoch 17, 50% \t train_loss: 0.009311 took: 1.22s\n",
      "Epoch 17, 60% \t train_loss: 0.008071 took: 1.29s\n",
      "Epoch 17, 70% \t train_loss: 0.005983 took: 1.15s\n",
      "Epoch 17, 80% \t train_loss: 0.008370 took: 1.27s\n",
      "Epoch 17, 90% \t train_loss: 0.005996 took: 1.21s\n",
      "Validation loss = 0.01\n",
      "Epoch 18, 10% \t train_loss: 0.008010 took: 1.83s\n",
      "Epoch 18, 20% \t train_loss: 0.008016 took: 1.18s\n",
      "Epoch 18, 30% \t train_loss: 0.008693 took: 1.20s\n",
      "Epoch 18, 40% \t train_loss: 0.008474 took: 1.32s\n",
      "Epoch 18, 50% \t train_loss: 0.009080 took: 1.31s\n",
      "Epoch 18, 60% \t train_loss: 0.006608 took: 1.22s\n",
      "Epoch 18, 70% \t train_loss: 0.007668 took: 1.26s\n",
      "Epoch 18, 80% \t train_loss: 0.007495 took: 1.19s\n",
      "Epoch 18, 90% \t train_loss: 0.006165 took: 1.25s\n",
      "Validation loss = 0.01\n",
      "Epoch 19, 10% \t train_loss: 0.006631 took: 1.87s\n",
      "Epoch 19, 20% \t train_loss: 0.005270 took: 1.19s\n",
      "Epoch 19, 30% \t train_loss: 0.005760 took: 1.23s\n",
      "Epoch 19, 40% \t train_loss: 0.007284 took: 1.23s\n",
      "Epoch 19, 50% \t train_loss: 0.006437 took: 1.27s\n",
      "Epoch 19, 60% \t train_loss: 0.007045 took: 1.24s\n",
      "Epoch 19, 70% \t train_loss: 0.007650 took: 1.17s\n",
      "Epoch 19, 80% \t train_loss: 0.010511 took: 1.24s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, 90% \t train_loss: 0.007176 took: 1.22s\n",
      "Validation loss = 0.01\n",
      "Epoch 20, 10% \t train_loss: 0.005668 took: 1.87s\n",
      "Epoch 20, 20% \t train_loss: 0.008720 took: 1.33s\n",
      "Epoch 20, 30% \t train_loss: 0.006293 took: 1.19s\n",
      "Epoch 20, 40% \t train_loss: 0.004814 took: 1.28s\n",
      "Epoch 20, 50% \t train_loss: 0.006440 took: 1.23s\n",
      "Epoch 20, 60% \t train_loss: 0.006062 took: 1.19s\n",
      "Epoch 20, 70% \t train_loss: 0.004907 took: 1.23s\n",
      "Epoch 20, 80% \t train_loss: 0.005867 took: 1.27s\n",
      "Epoch 20, 90% \t train_loss: 0.004979 took: 1.16s\n",
      "Validation loss = 0.01\n",
      "Training finished, took 328.44s\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "train, test, train_sampler, val_sampler = split_train_test(0.85)\n",
    "# Build and train CNN\n",
    "CNN = SimpleCNN()\n",
    "trainNet(CNN, batch_size=4, n_epochs=25, learning_rate=1e-7)#1e-6, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 38.] (10379, 1)\n",
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 1\n",
      "epochs= 10\n",
      "learning_rate= 1e-06\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Christian/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:55: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/Christian/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, 10% \t train_loss: 0.686015 took: 5.78s\n",
      "Epoch 1, 20% \t train_loss: 0.114861 took: 5.88s\n",
      "Epoch 1, 30% \t train_loss: 0.058533 took: 5.56s\n",
      "Epoch 1, 40% \t train_loss: 0.029541 took: 5.83s\n",
      "Epoch 1, 50% \t train_loss: 0.023492 took: 5.63s\n",
      "Epoch 1, 60% \t train_loss: 0.012049 took: 5.61s\n",
      "Epoch 1, 70% \t train_loss: 0.008899 took: 5.72s\n",
      "Epoch 1, 80% \t train_loss: 0.008658 took: 5.79s\n",
      "Epoch 1, 90% \t train_loss: 0.006027 took: 5.72s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Christian/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:75: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss = 0.00\n",
      "Training finished, took 61.95s\n",
      "Epoch 2, 10% \t train_loss: 0.002458 took: 5.88s\n",
      "Epoch 2, 20% \t train_loss: 0.002033 took: 5.74s\n",
      "Epoch 2, 30% \t train_loss: 0.002376 took: 5.80s\n",
      "Epoch 2, 40% \t train_loss: 0.004191 took: 5.90s\n",
      "Epoch 2, 50% \t train_loss: 0.004939 took: 5.88s\n",
      "Epoch 2, 60% \t train_loss: 0.002037 took: 5.92s\n",
      "Epoch 2, 70% \t train_loss: 0.002337 took: 6.43s\n",
      "Epoch 2, 80% \t train_loss: 0.000962 took: 5.90s\n",
      "Epoch 2, 90% \t train_loss: 0.001844 took: 5.93s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 125.61s\n",
      "Epoch 3, 10% \t train_loss: 0.000450 took: 6.14s\n",
      "Epoch 3, 20% \t train_loss: 0.002563 took: 5.64s\n",
      "Epoch 3, 30% \t train_loss: 0.002017 took: 5.76s\n",
      "Epoch 3, 40% \t train_loss: 0.000929 took: 5.67s\n",
      "Epoch 3, 50% \t train_loss: 0.000416 took: 5.66s\n",
      "Epoch 3, 60% \t train_loss: 0.000338 took: 5.72s\n",
      "Epoch 3, 70% \t train_loss: 0.000307 took: 5.73s\n",
      "Epoch 3, 80% \t train_loss: 0.000714 took: 5.88s\n",
      "Epoch 3, 90% \t train_loss: 0.000254 took: 5.79s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 187.83s\n",
      "Epoch 4, 10% \t train_loss: 0.000148 took: 5.97s\n",
      "Epoch 4, 20% \t train_loss: 0.000154 took: 6.04s\n",
      "Epoch 4, 30% \t train_loss: 0.000077 took: 6.33s\n",
      "Epoch 4, 40% \t train_loss: 0.000066 took: 5.93s\n",
      "Epoch 4, 50% \t train_loss: 0.000052 took: 6.26s\n",
      "Epoch 4, 60% \t train_loss: 0.001800 took: 6.04s\n",
      "Epoch 4, 70% \t train_loss: 0.000560 took: 5.98s\n",
      "Epoch 4, 80% \t train_loss: 0.000082 took: 6.13s\n",
      "Epoch 4, 90% \t train_loss: 0.000625 took: 6.15s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 253.46s\n",
      "Epoch 5, 10% \t train_loss: 0.000071 took: 6.11s\n",
      "Epoch 5, 20% \t train_loss: 0.000144 took: 5.79s\n",
      "Epoch 5, 30% \t train_loss: 0.000142 took: 5.88s\n",
      "Epoch 5, 40% \t train_loss: 0.000055 took: 5.93s\n",
      "Epoch 5, 50% \t train_loss: 0.000087 took: 5.88s\n",
      "Epoch 5, 60% \t train_loss: 0.000033 took: 6.02s\n",
      "Epoch 5, 70% \t train_loss: 0.000030 took: 6.05s\n",
      "Epoch 5, 80% \t train_loss: 0.000037 took: 5.95s\n",
      "Epoch 5, 90% \t train_loss: 0.000031 took: 5.91s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 317.33s\n",
      "Epoch 6, 10% \t train_loss: 0.000019 took: 6.43s\n",
      "Epoch 6, 20% \t train_loss: 0.000017 took: 5.91s\n",
      "Epoch 6, 30% \t train_loss: 0.000051 took: 5.89s\n",
      "Epoch 6, 40% \t train_loss: 0.000028 took: 5.92s\n",
      "Epoch 6, 50% \t train_loss: 0.000010 took: 5.94s\n",
      "Epoch 6, 60% \t train_loss: 0.000019 took: 6.04s\n",
      "Epoch 6, 70% \t train_loss: 0.000009 took: 6.02s\n",
      "Epoch 6, 80% \t train_loss: 0.000010 took: 5.90s\n",
      "Epoch 6, 90% \t train_loss: 0.000023 took: 6.15s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 382.37s\n",
      "Epoch 7, 10% \t train_loss: 0.000009 took: 6.15s\n",
      "Epoch 7, 20% \t train_loss: 0.000006 took: 6.13s\n",
      "Epoch 7, 30% \t train_loss: 0.000004 took: 5.96s\n",
      "Epoch 7, 40% \t train_loss: 0.000004 took: 6.14s\n",
      "Epoch 7, 50% \t train_loss: 0.000004 took: 6.03s\n",
      "Epoch 7, 60% \t train_loss: 0.000003 took: 6.00s\n",
      "Epoch 7, 70% \t train_loss: 0.000001 took: 6.10s\n",
      "Epoch 7, 80% \t train_loss: 0.000009 took: 6.09s\n",
      "Epoch 7, 90% \t train_loss: 0.000001 took: 6.26s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 448.05s\n",
      "Epoch 8, 10% \t train_loss: 0.000002 took: 6.11s\n",
      "Epoch 8, 20% \t train_loss: 0.000001 took: 5.86s\n",
      "Epoch 8, 30% \t train_loss: 0.000012 took: 5.85s\n",
      "Epoch 8, 40% \t train_loss: 0.000001 took: 5.93s\n",
      "Epoch 8, 50% \t train_loss: 0.000001 took: 5.90s\n",
      "Epoch 8, 60% \t train_loss: 0.000001 took: 5.88s\n",
      "Epoch 8, 70% \t train_loss: 0.000001 took: 6.11s\n",
      "Epoch 8, 80% \t train_loss: 0.000001 took: 6.09s\n",
      "Epoch 8, 90% \t train_loss: 0.000001 took: 6.09s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 512.62s\n",
      "Epoch 9, 10% \t train_loss: 0.000001 took: 6.13s\n",
      "Epoch 9, 20% \t train_loss: 0.000000 took: 5.89s\n",
      "Epoch 9, 30% \t train_loss: 0.000001 took: 5.93s\n",
      "Epoch 9, 40% \t train_loss: 0.000000 took: 6.02s\n",
      "Epoch 9, 50% \t train_loss: 0.000000 took: 5.85s\n",
      "Epoch 9, 60% \t train_loss: 0.000001 took: 5.93s\n",
      "Epoch 9, 70% \t train_loss: 0.000001 took: 5.88s\n",
      "Epoch 9, 80% \t train_loss: 0.000000 took: 5.94s\n",
      "Epoch 9, 90% \t train_loss: 0.000000 took: 6.03s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 576.68s\n",
      "Epoch 10, 10% \t train_loss: 0.000000 took: 6.33s\n",
      "Epoch 10, 20% \t train_loss: 0.000000 took: 6.07s\n",
      "Epoch 10, 30% \t train_loss: 0.000000 took: 6.05s\n",
      "Epoch 10, 40% \t train_loss: 0.000000 took: 5.82s\n",
      "Epoch 10, 50% \t train_loss: 0.000000 took: 5.89s\n",
      "Epoch 10, 60% \t train_loss: 0.000000 took: 6.30s\n",
      "Epoch 10, 70% \t train_loss: 0.000000 took: 6.09s\n",
      "Epoch 10, 80% \t train_loss: 0.000000 took: 6.04s\n",
      "Epoch 10, 90% \t train_loss: 0.000000 took: 6.03s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 642.13s\n",
      "[[ 1034.     0.]\n",
      " [  250.   500.]]\n",
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 1\n",
      "epochs= 10\n",
      "learning_rate= 1e-06\n",
      "==============================\n",
      "Epoch 1, 10% \t train_loss: 0.847614 took: 5.87s\n",
      "Epoch 1, 20% \t train_loss: 0.170719 took: 5.72s\n",
      "Epoch 1, 30% \t train_loss: 0.082757 took: 5.56s\n",
      "Epoch 1, 40% \t train_loss: 0.049638 took: 5.44s\n",
      "Epoch 1, 50% \t train_loss: 0.029748 took: 5.61s\n",
      "Epoch 1, 60% \t train_loss: 0.019024 took: 5.98s\n",
      "Epoch 1, 70% \t train_loss: 0.013303 took: 5.90s\n",
      "Epoch 1, 80% \t train_loss: 0.008324 took: 5.77s\n",
      "Epoch 1, 90% \t train_loss: 0.010088 took: 5.83s\n",
      "Validation loss = 0.01\n",
      "Training finished, took 62.12s\n",
      "Epoch 2, 10% \t train_loss: 0.007813 took: 5.87s\n",
      "Epoch 2, 20% \t train_loss: 0.003024 took: 5.57s\n",
      "Epoch 2, 30% \t train_loss: 0.003911 took: 5.75s\n",
      "Epoch 2, 40% \t train_loss: 0.001583 took: 5.68s\n",
      "Epoch 2, 50% \t train_loss: 0.001576 took: 5.71s\n",
      "Epoch 2, 60% \t train_loss: 0.002316 took: 5.88s\n",
      "Epoch 2, 70% \t train_loss: 0.002243 took: 5.78s\n",
      "Epoch 2, 80% \t train_loss: 0.001869 took: 5.93s\n",
      "Epoch 2, 90% \t train_loss: 0.004594 took: 5.74s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 124.45s\n",
      "Epoch 3, 10% \t train_loss: 0.000557 took: 5.93s\n",
      "Epoch 3, 20% \t train_loss: 0.002857 took: 5.48s\n",
      "Epoch 3, 30% \t train_loss: 0.001651 took: 5.68s\n",
      "Epoch 3, 40% \t train_loss: 0.000889 took: 6.14s\n",
      "Epoch 3, 50% \t train_loss: 0.000419 took: 6.26s\n",
      "Epoch 3, 60% \t train_loss: 0.000325 took: 6.03s\n",
      "Epoch 3, 70% \t train_loss: 0.000441 took: 5.97s\n",
      "Epoch 3, 80% \t train_loss: 0.000395 took: 6.10s\n",
      "Epoch 3, 90% \t train_loss: 0.000185 took: 5.91s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 188.54s\n",
      "Epoch 4, 10% \t train_loss: 0.000362 took: 6.01s\n",
      "Epoch 4, 20% \t train_loss: 0.000232 took: 5.64s\n",
      "Epoch 4, 30% \t train_loss: 0.000398 took: 5.78s\n",
      "Epoch 4, 40% \t train_loss: 0.000224 took: 5.81s\n",
      "Epoch 4, 50% \t train_loss: 0.000111 took: 5.83s\n",
      "Epoch 4, 60% \t train_loss: 0.000201 took: 5.90s\n",
      "Epoch 4, 70% \t train_loss: 0.000079 took: 5.79s\n",
      "Epoch 4, 80% \t train_loss: 0.001273 took: 5.75s\n",
      "Epoch 4, 90% \t train_loss: 0.000136 took: 5.89s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 251.36s\n",
      "Epoch 5, 10% \t train_loss: 0.000070 took: 5.92s\n",
      "Epoch 5, 20% \t train_loss: 0.000073 took: 5.57s\n",
      "Epoch 5, 30% \t train_loss: 0.000078 took: 5.73s\n",
      "Epoch 5, 40% \t train_loss: 0.000037 took: 5.71s\n",
      "Epoch 5, 50% \t train_loss: 0.000062 took: 5.76s\n",
      "Epoch 5, 60% \t train_loss: 0.000039 took: 6.02s\n",
      "Epoch 5, 70% \t train_loss: 0.000033 took: 5.97s\n",
      "Epoch 5, 80% \t train_loss: 0.000046 took: 6.01s\n",
      "Epoch 5, 90% \t train_loss: 0.000020 took: 5.92s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 314.58s\n",
      "Epoch 6, 10% \t train_loss: 0.000032 took: 5.98s\n",
      "Epoch 6, 20% \t train_loss: 0.000022 took: 5.58s\n",
      "Epoch 6, 30% \t train_loss: 0.000018 took: 5.86s\n",
      "Epoch 6, 40% \t train_loss: 0.000041 took: 5.83s\n",
      "Epoch 6, 50% \t train_loss: 0.000037 took: 5.90s\n",
      "Epoch 6, 60% \t train_loss: 0.000030 took: 6.07s\n",
      "Epoch 6, 70% \t train_loss: 0.000017 took: 6.03s\n",
      "Epoch 6, 80% \t train_loss: 0.000012 took: 6.11s\n",
      "Epoch 6, 90% \t train_loss: 0.000012 took: 6.09s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 378.67s\n",
      "Epoch 7, 10% \t train_loss: 0.000007 took: 6.06s\n",
      "Epoch 7, 20% \t train_loss: 0.000005 took: 5.92s\n",
      "Epoch 7, 30% \t train_loss: 0.000005 took: 5.90s\n",
      "Epoch 7, 40% \t train_loss: 0.000004 took: 6.00s\n",
      "Epoch 7, 50% \t train_loss: 0.000041 took: 6.01s\n",
      "Epoch 7, 60% \t train_loss: 0.000004 took: 6.09s\n",
      "Epoch 7, 70% \t train_loss: 0.000005 took: 6.03s\n",
      "Epoch 7, 80% \t train_loss: 0.000004 took: 6.11s\n",
      "Epoch 7, 90% \t train_loss: 0.000002 took: 6.05s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 443.57s\n",
      "Epoch 8, 10% \t train_loss: 0.000002 took: 6.58s\n",
      "Epoch 8, 20% \t train_loss: 0.000003 took: 6.23s\n",
      "Epoch 8, 30% \t train_loss: 0.000001 took: 6.11s\n",
      "Epoch 8, 40% \t train_loss: 0.000001 took: 6.02s\n",
      "Epoch 8, 50% \t train_loss: 0.000001 took: 6.07s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, 60% \t train_loss: 0.000001 took: 6.21s\n",
      "Epoch 8, 70% \t train_loss: 0.000001 took: 6.32s\n",
      "Epoch 8, 80% \t train_loss: 0.000001 took: 6.24s\n",
      "Epoch 8, 90% \t train_loss: 0.000005 took: 6.08s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 510.09s\n",
      "Epoch 9, 10% \t train_loss: 0.000000 took: 6.14s\n",
      "Epoch 9, 20% \t train_loss: 0.000001 took: 5.94s\n",
      "Epoch 9, 30% \t train_loss: 0.000000 took: 5.99s\n",
      "Epoch 9, 40% \t train_loss: 0.000000 took: 5.98s\n",
      "Epoch 9, 50% \t train_loss: 0.000000 took: 5.98s\n",
      "Epoch 9, 60% \t train_loss: 0.000001 took: 5.99s\n",
      "Epoch 9, 70% \t train_loss: 0.000000 took: 6.00s\n",
      "Epoch 9, 80% \t train_loss: 0.000000 took: 5.91s\n",
      "Epoch 9, 90% \t train_loss: 0.000001 took: 5.91s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 574.29s\n",
      "Epoch 10, 10% \t train_loss: 0.000000 took: 6.15s\n",
      "Epoch 10, 20% \t train_loss: 0.000000 took: 5.77s\n",
      "Epoch 10, 30% \t train_loss: 0.000000 took: 5.79s\n",
      "Epoch 10, 40% \t train_loss: 0.000000 took: 5.95s\n",
      "Epoch 10, 50% \t train_loss: 0.000000 took: 5.92s\n",
      "Epoch 10, 60% \t train_loss: 0.000000 took: 6.01s\n",
      "Epoch 10, 70% \t train_loss: 0.000000 took: 5.90s\n",
      "Epoch 10, 80% \t train_loss: 0.000000 took: 5.99s\n",
      "Epoch 10, 90% \t train_loss: 0.000000 took: 6.02s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 638.13s\n",
      "[[  2.06700000e+03   1.00000000e+00]\n",
      " [  5.00000000e+02   1.25000000e+03]]\n",
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 1\n",
      "epochs= 10\n",
      "learning_rate= 1e-06\n",
      "==============================\n",
      "Epoch 1, 10% \t train_loss: 0.792853 took: 5.76s\n",
      "Epoch 1, 20% \t train_loss: 0.097491 took: 5.40s\n",
      "Epoch 1, 30% \t train_loss: 0.044407 took: 5.61s\n",
      "Epoch 1, 40% \t train_loss: 0.028369 took: 5.62s\n",
      "Epoch 1, 50% \t train_loss: 0.017383 took: 5.66s\n",
      "Epoch 1, 60% \t train_loss: 0.016158 took: 5.82s\n",
      "Epoch 1, 70% \t train_loss: 0.009347 took: 5.83s\n",
      "Epoch 1, 80% \t train_loss: 0.007407 took: 5.75s\n",
      "Epoch 1, 90% \t train_loss: 0.005353 took: 5.80s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 61.64s\n",
      "Epoch 2, 10% \t train_loss: 0.002707 took: 6.39s\n",
      "Epoch 2, 20% \t train_loss: 0.002621 took: 5.75s\n",
      "Epoch 2, 30% \t train_loss: 0.002895 took: 5.96s\n",
      "Epoch 2, 40% \t train_loss: 0.004458 took: 5.58s\n",
      "Epoch 2, 50% \t train_loss: 0.004910 took: 5.83s\n",
      "Epoch 2, 60% \t train_loss: 0.001451 took: 5.95s\n",
      "Epoch 2, 70% \t train_loss: 0.000865 took: 5.64s\n",
      "Epoch 2, 80% \t train_loss: 0.002409 took: 6.07s\n",
      "Epoch 2, 90% \t train_loss: 0.001047 took: 5.85s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 124.96s\n",
      "Epoch 3, 10% \t train_loss: 0.000595 took: 5.94s\n",
      "Epoch 3, 20% \t train_loss: 0.000479 took: 5.85s\n",
      "Epoch 3, 30% \t train_loss: 0.000397 took: 5.71s\n",
      "Epoch 3, 40% \t train_loss: 0.000335 took: 5.61s\n",
      "Epoch 3, 50% \t train_loss: 0.003661 took: 5.92s\n",
      "Epoch 3, 60% \t train_loss: 0.000644 took: 5.76s\n",
      "Epoch 3, 70% \t train_loss: 0.000608 took: 5.81s\n",
      "Epoch 3, 80% \t train_loss: 0.000387 took: 5.72s\n",
      "Epoch 3, 90% \t train_loss: 0.000637 took: 5.90s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 187.36s\n",
      "Epoch 4, 10% \t train_loss: 0.000356 took: 5.75s\n",
      "Epoch 4, 20% \t train_loss: 0.000188 took: 5.69s\n",
      "Epoch 4, 30% \t train_loss: 0.000156 took: 5.82s\n",
      "Epoch 4, 40% \t train_loss: 0.002546 took: 5.89s\n",
      "Epoch 4, 50% \t train_loss: 0.000194 took: 5.85s\n",
      "Epoch 4, 60% \t train_loss: 0.000131 took: 5.76s\n",
      "Epoch 4, 70% \t train_loss: 0.000155 took: 5.95s\n",
      "Epoch 4, 80% \t train_loss: 0.000166 took: 5.83s\n",
      "Epoch 4, 90% \t train_loss: 0.000069 took: 5.96s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 250.39s\n",
      "Epoch 5, 10% \t train_loss: 0.000075 took: 5.97s\n",
      "Epoch 5, 20% \t train_loss: 0.000060 took: 5.68s\n",
      "Epoch 5, 30% \t train_loss: 0.000063 took: 5.80s\n",
      "Epoch 5, 40% \t train_loss: 0.000026 took: 5.80s\n",
      "Epoch 5, 50% \t train_loss: 0.000107 took: 5.75s\n",
      "Epoch 5, 60% \t train_loss: 0.001382 took: 5.85s\n",
      "Epoch 5, 70% \t train_loss: 0.000049 took: 5.88s\n",
      "Epoch 5, 80% \t train_loss: 0.000038 took: 5.97s\n",
      "Epoch 5, 90% \t train_loss: 0.000031 took: 5.97s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 313.64s\n",
      "Epoch 6, 10% \t train_loss: 0.000016 took: 5.94s\n",
      "Epoch 6, 20% \t train_loss: 0.000027 took: 5.74s\n",
      "Epoch 6, 30% \t train_loss: 0.000015 took: 5.72s\n",
      "Epoch 6, 40% \t train_loss: 0.000046 took: 5.87s\n",
      "Epoch 6, 50% \t train_loss: 0.000036 took: 5.81s\n",
      "Epoch 6, 60% \t train_loss: 0.000012 took: 5.90s\n",
      "Epoch 6, 70% \t train_loss: 0.000204 took: 5.88s\n",
      "Epoch 6, 80% \t train_loss: 0.000021 took: 5.87s\n",
      "Epoch 6, 90% \t train_loss: 0.000017 took: 6.03s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 376.78s\n",
      "Epoch 7, 10% \t train_loss: 0.000013 took: 6.00s\n",
      "Epoch 7, 20% \t train_loss: 0.000010 took: 5.75s\n",
      "Epoch 7, 30% \t train_loss: 0.000007 took: 5.95s\n",
      "Epoch 7, 40% \t train_loss: 0.000005 took: 5.87s\n",
      "Epoch 7, 50% \t train_loss: 0.000005 took: 5.89s\n",
      "Epoch 7, 60% \t train_loss: 0.000009 took: 6.12s\n",
      "Epoch 7, 70% \t train_loss: 0.000092 took: 6.09s\n",
      "Epoch 7, 80% \t train_loss: 0.000005 took: 6.13s\n",
      "Epoch 7, 90% \t train_loss: 0.000005 took: 6.25s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 441.40s\n",
      "Epoch 8, 10% \t train_loss: 0.000003 took: 6.85s\n",
      "Epoch 8, 20% \t train_loss: 0.000003 took: 6.30s\n",
      "Epoch 8, 30% \t train_loss: 0.000002 took: 5.91s\n",
      "Epoch 8, 40% \t train_loss: 0.000002 took: 6.22s\n",
      "Epoch 8, 50% \t train_loss: 0.000002 took: 6.23s\n",
      "Epoch 8, 60% \t train_loss: 0.000019 took: 6.09s\n",
      "Epoch 8, 70% \t train_loss: 0.000002 took: 6.46s\n",
      "Epoch 8, 80% \t train_loss: 0.000001 took: 6.29s\n",
      "Epoch 8, 90% \t train_loss: 0.000001 took: 6.17s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 508.56s\n",
      "Epoch 9, 10% \t train_loss: 0.000001 took: 6.51s\n",
      "Epoch 9, 20% \t train_loss: 0.000001 took: 6.19s\n",
      "Epoch 9, 30% \t train_loss: 0.000001 took: 5.79s\n",
      "Epoch 9, 40% \t train_loss: 0.000001 took: 5.82s\n",
      "Epoch 9, 50% \t train_loss: 0.000002 took: 5.81s\n",
      "Epoch 9, 60% \t train_loss: 0.000000 took: 5.75s\n",
      "Epoch 9, 70% \t train_loss: 0.000000 took: 6.09s\n",
      "Epoch 9, 80% \t train_loss: 0.000000 took: 6.11s\n",
      "Epoch 9, 90% \t train_loss: 0.000001 took: 5.79s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 573.11s\n",
      "Epoch 10, 10% \t train_loss: 0.000000 took: 6.36s\n",
      "Epoch 10, 20% \t train_loss: 0.000000 took: 6.12s\n",
      "Epoch 10, 30% \t train_loss: 0.000000 took: 5.77s\n",
      "Epoch 10, 40% \t train_loss: 0.000000 took: 5.80s\n",
      "Epoch 10, 50% \t train_loss: 0.000000 took: 5.79s\n",
      "Epoch 10, 60% \t train_loss: 0.000000 took: 6.12s\n",
      "Epoch 10, 70% \t train_loss: 0.000000 took: 6.04s\n",
      "Epoch 10, 80% \t train_loss: 0.000001 took: 5.93s\n",
      "Epoch 10, 90% \t train_loss: 0.000000 took: 6.16s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 637.94s\n",
      "[[  3.10100000e+03   1.00000000e+00]\n",
      " [  7.50000000e+02   2.00000000e+03]]\n",
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 1\n",
      "epochs= 10\n",
      "learning_rate= 1e-06\n",
      "==============================\n",
      "Epoch 1, 10% \t train_loss: 1.293249 took: 5.68s\n",
      "Epoch 1, 20% \t train_loss: 0.177816 took: 5.92s\n",
      "Epoch 1, 30% \t train_loss: 0.085512 took: 5.90s\n",
      "Epoch 1, 40% \t train_loss: 0.053094 took: 5.86s\n",
      "Epoch 1, 50% \t train_loss: 0.035873 took: 5.97s\n",
      "Epoch 1, 60% \t train_loss: 0.046994 took: 6.04s\n",
      "Epoch 1, 70% \t train_loss: 0.015978 took: 5.91s\n",
      "Epoch 1, 80% \t train_loss: 0.012532 took: 5.79s\n",
      "Epoch 1, 90% \t train_loss: 0.013406 took: 5.52s\n",
      "Validation loss = 0.01\n",
      "Training finished, took 62.70s\n",
      "Epoch 2, 10% \t train_loss: 0.006381 took: 5.74s\n",
      "Epoch 2, 20% \t train_loss: 0.006394 took: 5.61s\n",
      "Epoch 2, 30% \t train_loss: 0.006754 took: 5.82s\n",
      "Epoch 2, 40% \t train_loss: 0.004480 took: 6.11s\n",
      "Epoch 2, 50% \t train_loss: 0.003302 took: 5.88s\n",
      "Epoch 2, 60% \t train_loss: 0.002509 took: 5.76s\n",
      "Epoch 2, 70% \t train_loss: 0.004948 took: 5.80s\n",
      "Epoch 2, 80% \t train_loss: 0.011043 took: 5.78s\n",
      "Epoch 2, 90% \t train_loss: 0.002215 took: 5.76s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 125.31s\n",
      "Epoch 3, 10% \t train_loss: 0.002035 took: 6.35s\n",
      "Epoch 3, 20% \t train_loss: 0.003844 took: 5.75s\n",
      "Epoch 3, 30% \t train_loss: 0.001153 took: 5.99s\n",
      "Epoch 3, 40% \t train_loss: 0.001643 took: 6.09s\n",
      "Epoch 3, 50% \t train_loss: 0.000591 took: 5.79s\n",
      "Epoch 3, 60% \t train_loss: 0.000481 took: 5.77s\n",
      "Epoch 3, 70% \t train_loss: 0.001200 took: 5.81s\n",
      "Epoch 3, 80% \t train_loss: 0.001044 took: 6.07s\n",
      "Epoch 3, 90% \t train_loss: 0.000755 took: 5.95s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 189.23s\n",
      "Epoch 4, 10% \t train_loss: 0.000700 took: 5.92s\n",
      "Epoch 4, 20% \t train_loss: 0.001912 took: 5.58s\n",
      "Epoch 4, 30% \t train_loss: 0.000303 took: 5.59s\n",
      "Epoch 4, 40% \t train_loss: 0.000430 took: 5.64s\n",
      "Epoch 4, 50% \t train_loss: 0.000329 took: 5.69s\n",
      "Epoch 4, 60% \t train_loss: 0.000212 took: 5.82s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, 70% \t train_loss: 0.000363 took: 5.67s\n",
      "Epoch 4, 80% \t train_loss: 0.000182 took: 5.95s\n",
      "Epoch 4, 90% \t train_loss: 0.000112 took: 6.12s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 251.40s\n",
      "Epoch 5, 10% \t train_loss: 0.000109 took: 5.77s\n",
      "Epoch 5, 20% \t train_loss: 0.000094 took: 5.57s\n",
      "Epoch 5, 30% \t train_loss: 0.000096 took: 5.78s\n",
      "Epoch 5, 40% \t train_loss: 0.000099 took: 5.66s\n",
      "Epoch 5, 50% \t train_loss: 0.000051 took: 5.72s\n",
      "Epoch 5, 60% \t train_loss: 0.000082 took: 5.64s\n",
      "Epoch 5, 70% \t train_loss: 0.001114 took: 5.74s\n",
      "Epoch 5, 80% \t train_loss: 0.000075 took: 5.75s\n",
      "Epoch 5, 90% \t train_loss: 0.000043 took: 5.64s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 313.03s\n",
      "Epoch 6, 10% \t train_loss: 0.000023 took: 6.31s\n",
      "Epoch 6, 20% \t train_loss: 0.000108 took: 5.89s\n",
      "Epoch 6, 30% \t train_loss: 0.000029 took: 6.23s\n",
      "Epoch 6, 40% \t train_loss: 0.000039 took: 5.96s\n",
      "Epoch 6, 50% \t train_loss: 0.000027 took: 5.89s\n",
      "Epoch 6, 60% \t train_loss: 0.000020 took: 5.91s\n",
      "Epoch 6, 70% \t train_loss: 0.000015 took: 5.88s\n",
      "Epoch 6, 80% \t train_loss: 0.000037 took: 5.93s\n",
      "Epoch 6, 90% \t train_loss: 0.000014 took: 5.96s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 377.53s\n",
      "Epoch 7, 10% \t train_loss: 0.000010 took: 6.09s\n",
      "Epoch 7, 20% \t train_loss: 0.000014 took: 6.18s\n",
      "Epoch 7, 30% \t train_loss: 0.000020 took: 5.76s\n",
      "Epoch 7, 40% \t train_loss: 0.000011 took: 5.77s\n",
      "Epoch 7, 50% \t train_loss: 0.000036 took: 5.88s\n",
      "Epoch 7, 60% \t train_loss: 0.000009 took: 6.08s\n",
      "Epoch 7, 70% \t train_loss: 0.000007 took: 6.15s\n",
      "Epoch 7, 80% \t train_loss: 0.000004 took: 5.79s\n",
      "Epoch 7, 90% \t train_loss: 0.000009 took: 5.71s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 441.10s\n",
      "Epoch 8, 10% \t train_loss: 0.000004 took: 5.82s\n",
      "Epoch 8, 20% \t train_loss: 0.000004 took: 5.58s\n",
      "Epoch 8, 30% \t train_loss: 0.000002 took: 5.67s\n",
      "Epoch 8, 40% \t train_loss: 0.000003 took: 5.57s\n",
      "Epoch 8, 50% \t train_loss: 0.000007 took: 5.63s\n",
      "Epoch 8, 60% \t train_loss: 0.000002 took: 5.66s\n",
      "Epoch 8, 70% \t train_loss: 0.000002 took: 5.68s\n",
      "Epoch 8, 80% \t train_loss: 0.000002 took: 6.01s\n",
      "Epoch 8, 90% \t train_loss: 0.000001 took: 5.91s\n",
      "Validation loss = 0.00\n",
      "Training finished, took 503.17s\n",
      "Epoch 9, 10% \t train_loss: 0.000001 took: 6.15s\n",
      "Epoch 9, 20% \t train_loss: 0.000001 took: 5.67s\n",
      "Epoch 9, 30% \t train_loss: 0.000001 took: 5.71s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1074:\n",
      "Process Process-1073:\n",
      "Traceback (most recent call last):\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-21-8b7d5270fc24>\", line 9, in <module>\n",
      "    trainNet(CNN, train_sampler, batch_size=1, n_epochs=10, learning_rate=1e-6)# 2,5,1e-6\n",
      "  File \"<ipython-input-15-77bffaf0699d>\", line 37, in trainNet\n",
      "    for i, data in enumerate(train_loader, 0):\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 280, in __next__\n",
      "    idx, batch = self._get_batch()\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 259, in _get_batch\n",
      "    return self.data_queue.get()\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 66, in rebuild_storage_fd\n",
      "    def rebuild_storage_fd(cls, df, size):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "  File \"/home/Christian/anaconda2/envs/py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 5041) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "k_fold = 10\n",
    "train_sampler_list, test_sampler_list, train = split_train_test_kfold(k_fold=k_fold)\n",
    "\n",
    "cm = np.zeros((2,2))\n",
    "for train_sampler, test_sampler in zip(train_sampler_list, test_sampler_list):\n",
    "    CNN = SimpleCNN()\n",
    "    val_loader = torch.utils.data.DataLoader(train, batch_size=32, sampler=train_sampler, num_workers=2)\n",
    "    trainNet(CNN, train_sampler, batch_size=1, n_epochs=10, learning_rate=1e-6)# 2,5,1e-6 \n",
    "    cm += calculate_cm(test_sampler)\n",
    "    print(cm)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "fn=fn/250\n",
    "tp=tp/250\n",
    "acc = (tp+tn)/(tn+fp+fn+tp)\n",
    "sen = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "prec = tp/(tp+fp)\n",
    "F1 = 2 * (prec * sen) / (prec + sen)\n",
    "\n",
    "print(cm)\n",
    "print('accuracy: ',acc)\n",
    "print('sensitivity:', sen)\n",
    "print('specificity:', spec)\n",
    "print('precision:', prec)\n",
    "print('F1:', F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.03390000e+04   2.00000000e+00]\n",
      " [  2.25000000e+03   7.25000000e+03]]\n",
      "accuracy:  0.998940167646\n",
      "sensitivity: 0.763157894737\n",
      "specificity: 0.999806595107\n",
      "precision: 0.935483870968\n",
      "F1: 0.840579710145\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "fn=fn/250\n",
    "tp=tp/250\n",
    "acc = (tp+tn)/(tn+fp+fn+tp)\n",
    "sen = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "prec = tp/(tp+fp)\n",
    "F1 = 2 * (prec * sen) / (prec + sen)\n",
    "\n",
    "print(cm)\n",
    "print('accuracy: ',acc)\n",
    "print('sensitivity:', sen)\n",
    "print('specificity:', spec)\n",
    "print('precision:', prec)\n",
    "print('F1:', F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 99 %\n",
      "[[1551    1]\n",
      " [   2    4]]\n",
      "accuracy:  0.998074454429\n",
      "sensitivity: 0.666666666667\n",
      "specificity: 0.999355670103\n",
      "precision: 0.8\n",
      "F1: 0.727272727273\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(np.array(y_true), np.array(y_pred))\n",
    "    \n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "cm = np.zeros((2,2))\n",
    "total=0\n",
    "correct=0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data          \n",
    "        outputs = CNN(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        for x,y in zip(predicted, labels):\n",
    "            y_true.append(int(y.numpy()))\n",
    "            y_pred.append(int(x.numpy()))\n",
    "            \n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "cm = confusion_matrix(np.array(y_true), np.array(y_pred))\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "acc = (tp+tn)/(tn+fp+fn+tp)\n",
    "sen = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "prec = tp/(tp+fp)\n",
    "F1 = 2 * (prec * sen) / (prec + sen)\n",
    "\n",
    "print(cm)\n",
    "print('accuracy: ',acc)\n",
    "print('sensitivity:', sen)\n",
    "print('specificity:', spec)\n",
    "print('precision:', prec)\n",
    "print('F1:', F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "limit = 10e10\n",
    "for i, data in enumerate(test_loader):\n",
    "    if i > limit:\n",
    "        break\n",
    "    images, labels = data\n",
    "    for x,y in zip(images,labels):\n",
    "        x = x.numpy()\n",
    "        y = y.numpy()\n",
    "        outputs = CNN(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted = predicted.numpy()[0]\n",
    "        if y==1:\n",
    "            x=np.mean(x,axis=0)\n",
    "\n",
    "            plt.pcolormesh(np.arange(x.shape[1])*0.875,np.arange(x.shape[0]),x)\n",
    "            plt.ylabel('Frequency [Hz]')\n",
    "            plt.xlabel('Time [sec]')\n",
    "            plt.colorbar()\n",
    "            if y:\n",
    "                plt.title('Seizure Spectrogram (dB)')\n",
    "            else:\n",
    "                plt.title('Normal Spectrogram (dB)')\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
