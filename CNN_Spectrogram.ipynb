{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test CNN on spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%run scripts/readEDF.py\n",
    "%run scripts/spectrogramData.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8c4c037f90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_01.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_02.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_03.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_04.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_05.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_06.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_07.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_08.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_09.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_10.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_11.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_12.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_13.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_14.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_15.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_16.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_17.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_18.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_19.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_20.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_21.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_22.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_23.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_24.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_25.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_26.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_27.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_29.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_30.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_31.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_32.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_33.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_34.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_36.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_37.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_38.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_39.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_40.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_41.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_42.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_43.edf\n",
      "/mnt/c/Users/choec/Documents/GitHub/ANES212_data/chb01/chb01_46.edf\n"
     ]
    }
   ],
   "source": [
    "# Saving the organized data for use in CNN (python 3)\n",
    "%run scripts/readEDF.py\n",
    "df_dict = read_patient_edf('chb01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128.87664771080017\n",
      "(20802, 23, 128, 8) (20802, 1)\n"
     ]
    }
   ],
   "source": [
    "%run scripts/spectrogramData.py\n",
    "start = time.time()\n",
    "features, targets, dt = df_to_spectrogram_FT(df_dict, sliding=False, npserseg=256, noverlap=32, width=8, stft = True)\n",
    "print(time.time() - start)\n",
    "print(features.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize data into something useable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_kfold(features_og, targets_og, k_fold=1, num_repeat=250):\n",
    "#     features_og = np.load(feature_filename)\n",
    "#     targets_og = np.load(target_filename)\n",
    "    print(sum(targets_og),targets_og.shape)\n",
    "\n",
    "    # Split data into train and test\n",
    "    split = np.arange(len(targets_og))\n",
    "    np.random.shuffle(split)\n",
    "    features_og = features_og[split]\n",
    "    targets_og = targets_og[split]\n",
    "    features_og_0 = features_og[np.where(targets_og==0)[0]]\n",
    "    features_og_1 = features_og[np.where(targets_og==1)[0]]\n",
    "    targets_og_0 = targets_og[np.where(targets_og==0)[0]]\n",
    "    targets_og_1 = targets_og[np.where(targets_og==1)[0]]\n",
    "    N_0 = len(targets_og_0)\n",
    "    N_1 = len(targets_og_1)\n",
    "    \n",
    "    features_og_train = np.vstack([features_og_0,features_og_1])\n",
    "    targets_og_train = np.vstack([targets_og_0,targets_og_1])\n",
    "    sample_list = []\n",
    "    \n",
    "    num_seizure_per = float(N_1)//k_fold\n",
    "    num_remainder = float(N_1) % k_fold\n",
    "    for i in range(k_fold):\n",
    "        if (i+1)==k_fold:\n",
    "            temp1 = np.arange(i*N_0//k_fold,N_0, dtype=np.int64)\n",
    "            temp2 = np.arange(i*N_1//k_fold,N_1, dtype=np.int64)+N_0\n",
    "        else:\n",
    "            temp1 = np.arange(i*N_0//k_fold,(i+1)*N_0//k_fold, dtype=np.int64)\n",
    "            temp2 = np.arange(i*N_1//k_fold,(i+1)*N_1//k_fold, dtype=np.int64)+N_0\n",
    "        temp2 = np.repeat(temp2,num_repeat)\n",
    "        sample_list.append(np.hstack([temp1,temp2]))\n",
    "    \n",
    "    train_sampler_list = []\n",
    "    test_sampler_list = []\n",
    "    for i in range(k_fold):\n",
    "        temp = np.where(np.arange(len(sample_list), dtype=np.int64) != i)[0]\n",
    "        train =  np.hstack([sample_list[x] for x in temp])\n",
    "        test = sample_list[i]\n",
    "        train_sampler_list.append(SubsetRandomSampler(train))\n",
    "        test_sampler_list.append(SubsetRandomSampler(test))\n",
    "        \n",
    "    # Convert data to tensor dataset\n",
    "    features = torch.from_numpy(features_og_train).float()\n",
    "    targets = torch.from_numpy(targets_og_train).long()\n",
    "    targets = torch.squeeze(targets)\n",
    "    train = data_utils.TensorDataset(features, targets)\n",
    "    \n",
    "    return train_sampler_list, test_sampler_list, train\n",
    "    \n",
    "def split_train_test(train_percent, k_fold=0):\n",
    "    features_og = np.load('features_nonsliding_ch.npy')\n",
    "    targets_og = np.load('targets_nonsliding_ch.npy')\n",
    "    print(sum(targets_og),targets_og.shape)\n",
    "\n",
    "    # Split data into train and test\n",
    "    split = np.arange(len(targets_og))\n",
    "    np.random.shuffle(split)\n",
    "    features_og = features_og[split]\n",
    "    targets_og = targets_og[split]\n",
    "    features_og_0 = features_og[np.where(targets_og==0)[0]]\n",
    "    features_og_1 = features_og[np.where(targets_og==1)[0]]\n",
    "    targets_og_0 = targets_og[np.where(targets_og==0)[0]]\n",
    "    targets_og_1 = targets_og[np.where(targets_og==1)[0]]\n",
    "    N_0 = len(targets_og_0)\n",
    "    N_1 = len(targets_og_1)\n",
    "    \n",
    "    features_og_train = np.vstack([features_og_0[:int(train_percent*N_0)],features_og_1[:int(train_percent*N_1)]])\n",
    "    targets_og_train = np.vstack([targets_og_0[:int(train_percent*N_0)],targets_og_1[:int(train_percent*N_1)]])\n",
    "    features_og_test = np.vstack([features_og_0[int(train_percent*N_0):],features_og_1[int(train_percent*N_1):]])\n",
    "    targets_og_test = np.vstack([targets_og_0[int(train_percent*N_0):],targets_og_1[int(train_percent*N_1):]])\n",
    "    print(sum(targets_og_train), sum(targets_og_test))\n",
    "    \n",
    "\n",
    "    # Balance dataset\n",
    "    # ~1/4000 seizure events\n",
    "    idx = np.hstack([np.where(targets_og_train == 0)[0], \n",
    "                     np.repeat(np.where(targets_og_train == 1)[0], 100)]) # Oversample\n",
    "    features = features_og_train[idx]\n",
    "    targets = targets_og_train[idx]\n",
    "\n",
    "    # Convert data to tensor dataset\n",
    "    features = torch.from_numpy(features).float()\n",
    "    targets = torch.from_numpy(targets).long()\n",
    "    targets = torch.squeeze(targets)\n",
    "    train = data_utils.TensorDataset(features, targets)\n",
    "\n",
    "    N = features.size()[0]\n",
    "    sample_list = np.arange(N, dtype=np.int64)\n",
    "    np.random.shuffle(sample_list)\n",
    "    percent_train = 1.0\n",
    "\n",
    "    #Training\n",
    "    n_training_samples = int(N*percent_train)\n",
    "    train_sampler = SubsetRandomSampler(sample_list[:n_training_samples])\n",
    "\n",
    "    #Validation\n",
    "    val_sampler = SubsetRandomSampler(sample_list[:n_training_samples])\n",
    "\n",
    "    #Test data\n",
    "    features = torch.from_numpy(features_og_test).float()\n",
    "    targets = torch.from_numpy(targets_og_test).long()\n",
    "    targets = torch.squeeze(targets)\n",
    "    test = data_utils.TensorDataset(features, targets)\n",
    "    return train, test, train_sampler, val_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(torch.nn.Module):\n",
    "    \n",
    "    #Our batch shape for input x is (3, 32, 32)\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        #Input channels = 1, output channels = 18\n",
    "        self.conv1 = torch.nn.Conv2d(23, 18, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        #4608 input features, 64 output features (see sizing flow below)\n",
    "        self.fc1 = torch.nn.Linear(18 * 16 * 16, 64)\n",
    "        \n",
    "        #64 input features, 2 output features\n",
    "        self.fc2 = torch.nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #Computes the activation of the first convolution\n",
    "        #Size changes from (3, 32, 32) to (18, 32, 32)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        #Size changes from (18, 32, 32) to (18, 16, 16)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        #Reshape data to input to the input layer of the neural net\n",
    "        #Size changes from (18, 16, 16) to (1, 4608)\n",
    "        #Recall that the -1 infers this dimension from the other given dimension\n",
    "        x = x.view(-1, 18 * 16 *16)\n",
    "        \n",
    "        #Computes the activation of the first fully connected layer\n",
    "        #Size changes from (1, 4608) to (1, 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        #Computes the second fully connected layer (activation applied later)\n",
    "        #Size changes from (1, 64) to (1, 10)\n",
    "        x = self.fc2(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoader takes in a dataset and a sampler for loading (num_workers deals with system level memory) \n",
    "def get_train_loader(batch_size, train_sampler):\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size,\n",
    "                                           sampler=train_sampler, num_workers=2)\n",
    "    return(train_loader)\n",
    "\n",
    "#Test and validation loaders have constant batch sizes, so we can define them directly\n",
    "\n",
    "def trainNet(net, train_sampler, batch_size, n_epochs, learning_rate):\n",
    "    \n",
    "    #Print all of the hyperparameters of the training iteration:\n",
    "    print(\"===== HYPERPARAMETERS =====\")\n",
    "    print(\"batch_size=\", batch_size)\n",
    "    print(\"epochs=\", n_epochs)\n",
    "    print(\"learning_rate=\", learning_rate)\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    #Get training data\n",
    "    train_loader = get_train_loader(batch_size, train_sampler)\n",
    "    n_batches = len(train_loader)\n",
    "    \n",
    "    #Create our loss and optimizer functions\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    #Time for printing\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    #Loop for n_epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        print_every = n_batches // 10\n",
    "        start_time = time.time()\n",
    "        total_train_loss = 0.0\n",
    "        \n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            \n",
    "            #Get inputs\n",
    "            inputs, labels = data\n",
    "            \n",
    "            #Wrap them in a Variable object\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            \n",
    "            #Set the parameter gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #Forward pass, backward pass, optimize\n",
    "            outputs = net(inputs)\n",
    "            loss_size = loss(outputs, labels)\n",
    "            loss_size.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Print statistics\n",
    "            running_loss += loss_size.data[0]\n",
    "            total_train_loss += loss_size.data[0]\n",
    "            \n",
    "            #Print every 10th batch of an epoch\n",
    "            if (i + 1) % (print_every + 1) == 0:\n",
    "                print(\"Epoch {}, {:d}% \\t train_loss: {:.6f} took: {:.2f}s\".format(\n",
    "                        epoch+1, int(100 * (i+1) / n_batches), running_loss / print_every, time.time() - start_time))\n",
    "                #Reset running loss and time\n",
    "                running_loss = 0.0\n",
    "                start_time = time.time()\n",
    "            \n",
    "        #At the end of the epoch, do a pass on the validation set\n",
    "#         total_val_loss = 0\n",
    "#         for inputs, labels in val_loader:            \n",
    "#             #Wrap tensors in Variables\n",
    "#             inputs, labels = Variable(inputs), Variable(labels)\n",
    "            \n",
    "#             #Forward pass\n",
    "#             val_outputs = net(inputs)\n",
    "#             val_loss_size = loss(val_outputs, labels)\n",
    "#             total_val_loss += val_loss_size.data[0]\n",
    "            \n",
    "#         print(\"Validation loss = {:.2f}\".format(total_val_loss / max(1,len(val_loader))))\n",
    "        \n",
    "\n",
    "        print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))\n",
    "        \n",
    "def calculate_cm(test_sampler):\n",
    "    test_loader = torch.utils.data.DataLoader(train, sampler=test_sampler, batch_size=2)\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data          \n",
    "            outputs = CNN(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            for x,y in zip(predicted, labels):\n",
    "                y_true.append(int(y.numpy()))\n",
    "                y_pred.append(int(x.numpy()))\n",
    "    return confusion_matrix(np.array(y_true), np.array(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70.] (20802, 1)\n",
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 8\n",
      "epochs= 10\n",
      "learning_rate= 1e-06\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cachoe/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:55: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/cachoe/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, 10% \t train_loss: 1.289805 took: 7.05s\n",
      "Epoch 1, 20% \t train_loss: 0.381736 took: 3.68s\n",
      "Epoch 1, 30% \t train_loss: 0.274537 took: 3.56s\n",
      "Epoch 1, 40% \t train_loss: 0.217319 took: 3.25s\n",
      "Epoch 1, 50% \t train_loss: 0.165023 took: 3.24s\n",
      "Epoch 1, 60% \t train_loss: 0.135304 took: 3.49s\n",
      "Epoch 1, 70% \t train_loss: 0.113232 took: 3.33s\n",
      "Epoch 1, 80% \t train_loss: 0.093213 took: 3.24s\n",
      "Epoch 1, 90% \t train_loss: 0.083649 took: 3.15s\n",
      "Training finished, took 37.21s\n",
      "Epoch 2, 10% \t train_loss: 0.060304 took: 4.96s\n",
      "Epoch 2, 20% \t train_loss: 0.054846 took: 3.79s\n",
      "Epoch 2, 30% \t train_loss: 0.047181 took: 3.55s\n",
      "Epoch 2, 40% \t train_loss: 0.042093 took: 3.43s\n",
      "Epoch 2, 50% \t train_loss: 0.037386 took: 3.65s\n",
      "Epoch 2, 60% \t train_loss: 0.031432 took: 3.38s\n",
      "Epoch 2, 70% \t train_loss: 0.031330 took: 3.49s\n",
      "Epoch 2, 80% \t train_loss: 0.028859 took: 3.34s\n",
      "Epoch 2, 90% \t train_loss: 0.022574 took: 3.61s\n",
      "Training finished, took 73.64s\n",
      "Epoch 3, 10% \t train_loss: 0.021165 took: 4.77s\n",
      "Epoch 3, 20% \t train_loss: 0.016189 took: 3.71s\n",
      "Epoch 3, 30% \t train_loss: 0.017529 took: 3.22s\n",
      "Epoch 3, 40% \t train_loss: 0.016147 took: 3.26s\n",
      "Epoch 3, 50% \t train_loss: 0.014873 took: 3.20s\n",
      "Epoch 3, 60% \t train_loss: 0.014279 took: 3.74s\n",
      "Epoch 3, 70% \t train_loss: 0.010155 took: 3.71s\n",
      "Epoch 3, 80% \t train_loss: 0.010850 took: 3.65s\n",
      "Epoch 3, 90% \t train_loss: 0.012743 took: 3.56s\n",
      "Training finished, took 109.75s\n",
      "Epoch 4, 10% \t train_loss: 0.008027 took: 4.60s\n",
      "Epoch 4, 20% \t train_loss: 0.010940 took: 3.83s\n",
      "Epoch 4, 30% \t train_loss: 0.009932 took: 3.87s\n",
      "Epoch 4, 40% \t train_loss: 0.008269 took: 3.58s\n",
      "Epoch 4, 50% \t train_loss: 0.005586 took: 3.72s\n",
      "Epoch 4, 60% \t train_loss: 0.006724 took: 3.40s\n",
      "Epoch 4, 70% \t train_loss: 0.004999 took: 3.46s\n",
      "Epoch 4, 80% \t train_loss: 0.004778 took: 3.66s\n",
      "Epoch 4, 90% \t train_loss: 0.006121 took: 3.90s\n",
      "Training finished, took 147.04s\n",
      "Epoch 5, 10% \t train_loss: 0.004697 took: 5.14s\n",
      "Epoch 5, 20% \t train_loss: 0.003793 took: 3.89s\n",
      "Epoch 5, 30% \t train_loss: 0.005206 took: 3.57s\n",
      "Epoch 5, 40% \t train_loss: 0.004726 took: 3.23s\n",
      "Epoch 5, 50% \t train_loss: 0.004423 took: 3.48s\n",
      "Epoch 5, 60% \t train_loss: 0.005247 took: 3.44s\n",
      "Epoch 5, 70% \t train_loss: 0.002904 took: 3.47s\n",
      "Epoch 5, 80% \t train_loss: 0.003651 took: 3.33s\n",
      "Epoch 5, 90% \t train_loss: 0.003356 took: 3.53s\n",
      "Training finished, took 183.39s\n",
      "Epoch 6, 10% \t train_loss: 0.003723 took: 4.89s\n",
      "Epoch 6, 20% \t train_loss: 0.002679 took: 3.73s\n",
      "Epoch 6, 30% \t train_loss: 0.002777 took: 3.51s\n",
      "Epoch 6, 40% \t train_loss: 0.003476 took: 3.26s\n",
      "Epoch 6, 50% \t train_loss: 0.004506 took: 3.35s\n",
      "Epoch 6, 60% \t train_loss: 0.002281 took: 3.16s\n",
      "Epoch 6, 70% \t train_loss: 0.003066 took: 3.34s\n",
      "Epoch 6, 80% \t train_loss: 0.002035 took: 3.45s\n",
      "Epoch 6, 90% \t train_loss: 0.001686 took: 3.35s\n",
      "Training finished, took 218.96s\n",
      "Epoch 7, 10% \t train_loss: 0.002601 took: 4.87s\n",
      "Epoch 7, 20% \t train_loss: 0.002199 took: 3.70s\n",
      "Epoch 7, 30% \t train_loss: 0.001526 took: 3.70s\n",
      "Epoch 7, 40% \t train_loss: 0.002763 took: 3.53s\n",
      "Epoch 7, 50% \t train_loss: 0.002341 took: 3.60s\n",
      "Epoch 7, 60% \t train_loss: 0.001983 took: 3.53s\n",
      "Epoch 7, 70% \t train_loss: 0.002911 took: 3.35s\n",
      "Epoch 7, 80% \t train_loss: 0.001280 took: 4.03s\n",
      "Epoch 7, 90% \t train_loss: 0.001588 took: 4.11s\n",
      "Training finished, took 257.27s\n",
      "Epoch 8, 10% \t train_loss: 0.001389 took: 4.95s\n",
      "Epoch 8, 20% \t train_loss: 0.001130 took: 3.72s\n",
      "Epoch 8, 30% \t train_loss: 0.001063 took: 3.65s\n",
      "Epoch 8, 40% \t train_loss: 0.001497 took: 3.59s\n",
      "Epoch 8, 50% \t train_loss: 0.001244 took: 3.48s\n",
      "Epoch 8, 60% \t train_loss: 0.001750 took: 4.12s\n",
      "Epoch 8, 70% \t train_loss: 0.000954 took: 3.45s\n",
      "Epoch 8, 80% \t train_loss: 0.001219 took: 3.69s\n",
      "Epoch 8, 90% \t train_loss: 0.001672 took: 3.61s\n",
      "Training finished, took 295.11s\n",
      "Epoch 9, 10% \t train_loss: 0.000813 took: 5.39s\n",
      "Epoch 9, 20% \t train_loss: 0.001507 took: 3.90s\n",
      "Epoch 9, 30% \t train_loss: 0.000774 took: 3.57s\n",
      "Epoch 9, 40% \t train_loss: 0.001324 took: 3.96s\n",
      "Epoch 9, 50% \t train_loss: 0.001113 took: 3.40s\n",
      "Epoch 9, 60% \t train_loss: 0.001997 took: 3.32s\n",
      "Epoch 9, 70% \t train_loss: 0.000685 took: 3.40s\n",
      "Epoch 9, 80% \t train_loss: 0.000811 took: 3.29s\n",
      "Epoch 9, 90% \t train_loss: 0.000839 took: 3.32s\n",
      "Training finished, took 332.14s\n",
      "Epoch 10, 10% \t train_loss: 0.000941 took: 5.26s\n",
      "Epoch 10, 20% \t train_loss: 0.000624 took: 3.78s\n",
      "Epoch 10, 30% \t train_loss: 0.000626 took: 3.85s\n",
      "Epoch 10, 40% \t train_loss: 0.000864 took: 3.57s\n",
      "Epoch 10, 50% \t train_loss: 0.000546 took: 3.48s\n",
      "Epoch 10, 60% \t train_loss: 0.000503 took: 3.51s\n",
      "Epoch 10, 70% \t train_loss: 0.001822 took: 3.58s\n",
      "Epoch 10, 80% \t train_loss: 0.000480 took: 3.30s\n",
      "Epoch 10, 90% \t train_loss: 0.000874 took: 4.00s\n",
      "Training finished, took 369.79s\n",
      "[[4146.    0.]\n",
      " [ 250. 3250.]]\n",
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 8\n",
      "epochs= 10\n",
      "learning_rate= 1e-06\n",
      "==============================\n",
      "Epoch 1, 10% \t train_loss: 1.379585 took: 5.74s\n",
      "Epoch 1, 20% \t train_loss: 0.470035 took: 3.19s\n",
      "Epoch 1, 30% \t train_loss: 0.294737 took: 3.21s\n",
      "Epoch 1, 40% \t train_loss: 0.214804 took: 3.22s\n",
      "Epoch 1, 50% \t train_loss: 0.169677 took: 3.21s\n",
      "Epoch 1, 60% \t train_loss: 0.131529 took: 3.24s\n",
      "Epoch 1, 70% \t train_loss: 0.112554 took: 3.20s\n",
      "Epoch 1, 80% \t train_loss: 0.092533 took: 3.26s\n",
      "Epoch 1, 90% \t train_loss: 0.086011 took: 3.18s\n",
      "Training finished, took 34.65s\n",
      "Epoch 2, 10% \t train_loss: 0.065071 took: 4.61s\n",
      "Epoch 2, 20% \t train_loss: 0.056306 took: 3.69s\n",
      "Epoch 2, 30% \t train_loss: 0.048046 took: 3.31s\n",
      "Epoch 2, 40% \t train_loss: 0.043115 took: 3.24s\n",
      "Epoch 2, 50% \t train_loss: 0.036765 took: 3.25s\n",
      "Epoch 2, 60% \t train_loss: 0.035663 took: 3.25s\n",
      "Epoch 2, 70% \t train_loss: 0.032197 took: 3.32s\n",
      "Epoch 2, 80% \t train_loss: 0.028100 took: 3.30s\n",
      "Epoch 2, 90% \t train_loss: 0.024920 took: 3.20s\n",
      "Training finished, took 68.94s\n",
      "Epoch 3, 10% \t train_loss: 0.020634 took: 4.51s\n",
      "Epoch 3, 20% \t train_loss: 0.023400 took: 3.33s\n",
      "Epoch 3, 30% \t train_loss: 0.019804 took: 3.28s\n",
      "Epoch 3, 40% \t train_loss: 0.020936 took: 3.18s\n",
      "Epoch 3, 50% \t train_loss: 0.018967 took: 3.37s\n",
      "Epoch 3, 60% \t train_loss: 0.013300 took: 3.61s\n",
      "Epoch 3, 70% \t train_loss: 0.015179 took: 3.66s\n",
      "Epoch 3, 80% \t train_loss: 0.010902 took: 3.56s\n",
      "Epoch 3, 90% \t train_loss: 0.012057 took: 3.60s\n",
      "Training finished, took 104.34s\n",
      "Epoch 4, 10% \t train_loss: 0.010870 took: 4.66s\n",
      "Epoch 4, 20% \t train_loss: 0.008313 took: 3.71s\n",
      "Epoch 4, 30% \t train_loss: 0.010732 took: 3.25s\n",
      "Epoch 4, 40% \t train_loss: 0.007396 took: 3.20s\n",
      "Epoch 4, 50% \t train_loss: 0.012143 took: 3.32s\n",
      "Epoch 4, 60% \t train_loss: 0.010341 took: 3.49s\n",
      "Epoch 4, 70% \t train_loss: 0.008006 took: 3.65s\n",
      "Epoch 4, 80% \t train_loss: 0.007437 took: 3.39s\n",
      "Epoch 4, 90% \t train_loss: 0.007295 took: 3.37s\n",
      "Training finished, took 139.67s\n",
      "Epoch 5, 10% \t train_loss: 0.006243 took: 4.88s\n",
      "Epoch 5, 20% \t train_loss: 0.006369 took: 3.86s\n",
      "Epoch 5, 30% \t train_loss: 0.007809 took: 3.89s\n",
      "Epoch 5, 40% \t train_loss: 0.007012 took: 4.03s\n",
      "Epoch 5, 50% \t train_loss: 0.006924 took: 3.81s\n",
      "Epoch 5, 60% \t train_loss: 0.003750 took: 3.49s\n",
      "Epoch 5, 70% \t train_loss: 0.004174 took: 3.39s\n",
      "Epoch 5, 80% \t train_loss: 0.004564 took: 3.71s\n",
      "Epoch 5, 90% \t train_loss: 0.004979 took: 3.73s\n",
      "Training finished, took 178.08s\n",
      "Epoch 6, 10% \t train_loss: 0.003011 took: 5.39s\n",
      "Epoch 6, 20% \t train_loss: 0.002747 took: 3.62s\n",
      "Epoch 6, 30% \t train_loss: 0.005140 took: 3.49s\n",
      "Epoch 6, 40% \t train_loss: 0.003401 took: 3.61s\n",
      "Epoch 6, 50% \t train_loss: 0.005271 took: 3.60s\n",
      "Epoch 6, 60% \t train_loss: 0.004107 took: 3.82s\n",
      "Epoch 6, 70% \t train_loss: 0.005301 took: 4.19s\n",
      "Epoch 6, 80% \t train_loss: 0.004543 took: 4.93s\n",
      "Epoch 6, 90% \t train_loss: 0.003413 took: 3.58s\n",
      "Training finished, took 217.99s\n",
      "Epoch 7, 10% \t train_loss: 0.002046 took: 5.03s\n",
      "Epoch 7, 20% \t train_loss: 0.002027 took: 3.65s\n",
      "Epoch 7, 30% \t train_loss: 0.003513 took: 3.63s\n",
      "Epoch 7, 40% \t train_loss: 0.003805 took: 3.38s\n",
      "Epoch 7, 50% \t train_loss: 0.002788 took: 3.36s\n",
      "Epoch 7, 60% \t train_loss: 0.002459 took: 3.33s\n",
      "Epoch 7, 70% \t train_loss: 0.003310 took: 4.12s\n",
      "Epoch 7, 80% \t train_loss: 0.002775 took: 3.99s\n",
      "Epoch 7, 90% \t train_loss: 0.002660 took: 3.74s\n",
      "Training finished, took 255.89s\n",
      "Epoch 8, 10% \t train_loss: 0.001529 took: 4.93s\n",
      "Epoch 8, 20% \t train_loss: 0.002216 took: 3.85s\n",
      "Epoch 8, 30% \t train_loss: 0.001919 took: 3.48s\n",
      "Epoch 8, 40% \t train_loss: 0.002427 took: 3.68s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, 50% \t train_loss: 0.002882 took: 3.20s\n",
      "Epoch 8, 60% \t train_loss: 0.001491 took: 3.52s\n",
      "Epoch 8, 70% \t train_loss: 0.001583 took: 3.13s\n",
      "Epoch 8, 80% \t train_loss: 0.004057 took: 3.22s\n",
      "Epoch 8, 90% \t train_loss: 0.002075 took: 3.46s\n",
      "Training finished, took 291.66s\n",
      "Epoch 9, 10% \t train_loss: 0.001578 took: 4.92s\n",
      "Epoch 9, 20% \t train_loss: 0.001198 took: 3.47s\n",
      "Epoch 9, 30% \t train_loss: 0.003437 took: 3.24s\n",
      "Epoch 9, 40% \t train_loss: 0.000906 took: 3.24s\n",
      "Epoch 9, 50% \t train_loss: 0.002323 took: 3.26s\n",
      "Epoch 9, 60% \t train_loss: 0.002585 took: 3.44s\n",
      "Epoch 9, 70% \t train_loss: 0.001559 took: 3.75s\n",
      "Epoch 9, 80% \t train_loss: 0.000987 took: 3.22s\n",
      "Epoch 9, 90% \t train_loss: 0.000923 took: 3.24s\n",
      "Training finished, took 326.62s\n",
      "Epoch 10, 10% \t train_loss: 0.001207 took: 5.01s\n",
      "Epoch 10, 20% \t train_loss: 0.003666 took: 3.84s\n",
      "Epoch 10, 30% \t train_loss: 0.001234 took: 3.28s\n",
      "Epoch 10, 40% \t train_loss: 0.001399 took: 3.62s\n",
      "Epoch 10, 50% \t train_loss: 0.000833 took: 3.40s\n",
      "Epoch 10, 60% \t train_loss: 0.001202 took: 3.56s\n",
      "Epoch 10, 70% \t train_loss: 0.001392 took: 3.46s\n",
      "Epoch 10, 80% \t train_loss: 0.000715 took: 3.68s\n",
      "Epoch 10, 90% \t train_loss: 0.001042 took: 3.60s\n",
      "Training finished, took 363.43s\n",
      "[[8.288e+03 4.000e+00]\n",
      " [5.000e+02 6.500e+03]]\n",
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 8\n",
      "epochs= 10\n",
      "learning_rate= 1e-06\n",
      "==============================\n",
      "Epoch 1, 10% \t train_loss: 1.265676 took: 5.67s\n",
      "Epoch 1, 20% \t train_loss: 0.415431 took: 3.14s\n",
      "Epoch 1, 30% \t train_loss: 0.329318 took: 3.32s\n",
      "Epoch 1, 40% \t train_loss: 0.250097 took: 3.29s\n",
      "Epoch 1, 50% \t train_loss: 0.215177 took: 3.19s\n",
      "Epoch 1, 60% \t train_loss: 0.178278 took: 3.48s\n",
      "Epoch 1, 70% \t train_loss: 0.153341 took: 3.33s\n",
      "Epoch 1, 80% \t train_loss: 0.138936 took: 3.52s\n",
      "Epoch 1, 90% \t train_loss: 0.115345 took: 3.30s\n",
      "Training finished, took 35.69s\n",
      "Epoch 2, 10% \t train_loss: 0.083106 took: 5.07s\n",
      "Epoch 2, 20% \t train_loss: 0.079606 took: 3.44s\n",
      "Epoch 2, 30% \t train_loss: 0.072160 took: 3.57s\n",
      "Epoch 2, 40% \t train_loss: 0.062301 took: 3.36s\n",
      "Epoch 2, 50% \t train_loss: 0.054839 took: 3.46s\n",
      "Epoch 2, 60% \t train_loss: 0.048891 took: 3.94s\n",
      "Epoch 2, 70% \t train_loss: 0.044535 took: 3.77s\n",
      "Epoch 2, 80% \t train_loss: 0.038975 took: 3.41s\n",
      "Epoch 2, 90% \t train_loss: 0.036243 took: 3.75s\n",
      "Training finished, took 72.59s\n",
      "Epoch 3, 10% \t train_loss: 0.026969 took: 4.39s\n",
      "Epoch 3, 20% \t train_loss: 0.025763 took: 3.08s\n",
      "Epoch 3, 30% \t train_loss: 0.024598 took: 3.35s\n",
      "Epoch 3, 40% \t train_loss: 0.022230 took: 3.56s\n",
      "Epoch 3, 50% \t train_loss: 0.020899 took: 3.75s\n",
      "Epoch 3, 60% \t train_loss: 0.019274 took: 3.49s\n",
      "Epoch 3, 70% \t train_loss: 0.020079 took: 3.53s\n",
      "Epoch 3, 80% \t train_loss: 0.014808 took: 3.68s\n",
      "Epoch 3, 90% \t train_loss: 0.020843 took: 3.17s\n",
      "Training finished, took 108.49s\n",
      "Epoch 4, 10% \t train_loss: 0.014703 took: 4.78s\n",
      "Epoch 4, 20% \t train_loss: 0.011876 took: 3.34s\n",
      "Epoch 4, 30% \t train_loss: 0.013299 took: 3.55s\n",
      "Epoch 4, 40% \t train_loss: 0.011636 took: 3.83s\n",
      "Epoch 4, 50% \t train_loss: 0.011131 took: 3.55s\n",
      "Epoch 4, 60% \t train_loss: 0.008736 took: 3.44s\n",
      "Epoch 4, 70% \t train_loss: 0.007705 took: 3.41s\n",
      "Epoch 4, 80% \t train_loss: 0.008636 took: 3.78s\n",
      "Epoch 4, 90% \t train_loss: 0.008890 took: 3.33s\n",
      "Training finished, took 144.61s\n",
      "Epoch 5, 10% \t train_loss: 0.007050 took: 4.44s\n",
      "Epoch 5, 20% \t train_loss: 0.010043 took: 3.16s\n",
      "Epoch 5, 30% \t train_loss: 0.007693 took: 3.10s\n",
      "Epoch 5, 40% \t train_loss: 0.005430 took: 4.00s\n",
      "Epoch 5, 50% \t train_loss: 0.005321 took: 3.61s\n",
      "Epoch 5, 60% \t train_loss: 0.005441 took: 3.71s\n",
      "Epoch 5, 70% \t train_loss: 0.004089 took: 4.27s\n",
      "Epoch 5, 80% \t train_loss: 0.004087 took: 3.33s\n",
      "Epoch 5, 90% \t train_loss: 0.005725 took: 4.23s\n",
      "Training finished, took 182.79s\n",
      "Epoch 6, 10% \t train_loss: 0.005426 took: 4.83s\n",
      "Epoch 6, 20% \t train_loss: 0.004470 took: 3.75s\n",
      "Epoch 6, 30% \t train_loss: 0.003085 took: 3.94s\n",
      "Epoch 6, 40% \t train_loss: 0.002702 took: 4.37s\n",
      "Epoch 6, 50% \t train_loss: 0.005377 took: 3.55s\n",
      "Epoch 6, 60% \t train_loss: 0.004973 took: 3.37s\n",
      "Epoch 6, 70% \t train_loss: 0.003126 took: 3.52s\n",
      "Epoch 6, 80% \t train_loss: 0.007277 took: 3.54s\n",
      "Epoch 6, 90% \t train_loss: 0.004396 took: 3.69s\n",
      "Training finished, took 221.05s\n",
      "Epoch 7, 10% \t train_loss: 0.002627 took: 5.54s\n",
      "Epoch 7, 20% \t train_loss: 0.002855 took: 3.67s\n",
      "Epoch 7, 30% \t train_loss: 0.005388 took: 3.89s\n",
      "Epoch 7, 40% \t train_loss: 0.003874 took: 3.69s\n",
      "Epoch 7, 50% \t train_loss: 0.003305 took: 4.11s\n",
      "Epoch 7, 60% \t train_loss: 0.002503 took: 3.52s\n",
      "Epoch 7, 70% \t train_loss: 0.004403 took: 3.35s\n",
      "Epoch 7, 80% \t train_loss: 0.002204 took: 3.29s\n",
      "Epoch 7, 90% \t train_loss: 0.004042 took: 3.54s\n",
      "Training finished, took 259.27s\n",
      "Epoch 8, 10% \t train_loss: 0.005032 took: 5.36s\n",
      "Epoch 8, 20% \t train_loss: 0.002626 took: 3.47s\n",
      "Epoch 8, 30% \t train_loss: 0.001818 took: 3.43s\n",
      "Epoch 8, 40% \t train_loss: 0.003010 took: 3.87s\n",
      "Epoch 8, 50% \t train_loss: 0.002480 took: 3.47s\n",
      "Epoch 8, 60% \t train_loss: 0.001899 took: 4.30s\n",
      "Epoch 8, 70% \t train_loss: 0.002727 took: 3.86s\n",
      "Epoch 8, 80% \t train_loss: 0.001707 took: 3.23s\n",
      "Epoch 8, 90% \t train_loss: 0.001892 took: 3.66s\n",
      "Training finished, took 297.16s\n",
      "Epoch 9, 10% \t train_loss: 0.003466 took: 4.55s\n",
      "Epoch 9, 20% \t train_loss: 0.002869 took: 3.59s\n",
      "Epoch 9, 30% \t train_loss: 0.002504 took: 3.46s\n",
      "Epoch 9, 40% \t train_loss: 0.002707 took: 3.77s\n",
      "Epoch 9, 50% \t train_loss: 0.001313 took: 3.55s\n",
      "Epoch 9, 60% \t train_loss: 0.003067 took: 3.48s\n",
      "Epoch 9, 70% \t train_loss: 0.001523 took: 3.44s\n",
      "Epoch 9, 80% \t train_loss: 0.001139 took: 3.57s\n",
      "Epoch 9, 90% \t train_loss: 0.001436 took: 3.68s\n",
      "Training finished, took 333.62s\n",
      "Epoch 10, 10% \t train_loss: 0.000964 took: 4.48s\n",
      "Epoch 10, 20% \t train_loss: 0.000905 took: 3.20s\n",
      "Epoch 10, 30% \t train_loss: 0.002191 took: 3.39s\n",
      "Epoch 10, 40% \t train_loss: 0.002575 took: 3.56s\n",
      "Epoch 10, 50% \t train_loss: 0.001165 took: 3.70s\n",
      "Epoch 10, 60% \t train_loss: 0.001865 took: 3.39s\n",
      "Epoch 10, 70% \t train_loss: 0.001172 took: 3.28s\n",
      "Epoch 10, 80% \t train_loss: 0.002873 took: 3.21s\n",
      "Epoch 10, 90% \t train_loss: 0.002446 took: 3.41s\n",
      "Training finished, took 368.49s\n",
      "[[1.2433e+04 6.0000e+00]\n",
      " [7.5000e+02 9.7500e+03]]\n",
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 8\n",
      "epochs= 10\n",
      "learning_rate= 1e-06\n",
      "==============================\n",
      "Epoch 1, 10% \t train_loss: 0.977229 took: 5.58s\n",
      "Epoch 1, 20% \t train_loss: 0.362784 took: 3.35s\n",
      "Epoch 1, 30% \t train_loss: 0.261074 took: 3.21s\n",
      "Epoch 1, 40% \t train_loss: 0.200275 took: 3.52s\n",
      "Epoch 1, 50% \t train_loss: 0.159628 took: 3.66s\n",
      "Epoch 1, 60% \t train_loss: 0.128358 took: 3.67s\n",
      "Epoch 1, 70% \t train_loss: 0.097601 took: 3.68s\n",
      "Epoch 1, 80% \t train_loss: 0.082598 took: 3.82s\n",
      "Epoch 1, 90% \t train_loss: 0.068441 took: 3.32s\n",
      "Training finished, took 37.48s\n",
      "Epoch 2, 10% \t train_loss: 0.049728 took: 4.96s\n",
      "Epoch 2, 20% \t train_loss: 0.047475 took: 3.67s\n",
      "Epoch 2, 30% \t train_loss: 0.036126 took: 3.15s\n",
      "Epoch 2, 40% \t train_loss: 0.033061 took: 3.47s\n",
      "Epoch 2, 50% \t train_loss: 0.032540 took: 3.49s\n",
      "Epoch 2, 60% \t train_loss: 0.027439 took: 3.39s\n",
      "Epoch 2, 70% \t train_loss: 0.021986 took: 3.48s\n",
      "Epoch 2, 80% \t train_loss: 0.022276 took: 3.39s\n",
      "Epoch 2, 90% \t train_loss: 0.020057 took: 3.34s\n",
      "Training finished, took 73.31s\n",
      "Epoch 3, 10% \t train_loss: 0.015862 took: 4.67s\n",
      "Epoch 3, 20% \t train_loss: 0.014835 took: 3.22s\n",
      "Epoch 3, 30% \t train_loss: 0.013305 took: 3.22s\n",
      "Epoch 3, 40% \t train_loss: 0.011717 took: 3.31s\n",
      "Epoch 3, 50% \t train_loss: 0.014653 took: 3.11s\n",
      "Epoch 3, 60% \t train_loss: 0.012467 took: 3.86s\n",
      "Epoch 3, 70% \t train_loss: 0.011575 took: 3.90s\n",
      "Epoch 3, 80% \t train_loss: 0.011261 took: 4.28s\n",
      "Epoch 3, 90% \t train_loss: 0.009686 took: 3.60s\n",
      "Training finished, took 109.69s\n",
      "Epoch 4, 10% \t train_loss: 0.010177 took: 4.23s\n",
      "Epoch 4, 20% \t train_loss: 0.007768 took: 3.19s\n",
      "Epoch 4, 30% \t train_loss: 0.007610 took: 3.19s\n",
      "Epoch 4, 40% \t train_loss: 0.010109 took: 3.41s\n",
      "Epoch 4, 50% \t train_loss: 0.006788 took: 3.32s\n",
      "Epoch 4, 60% \t train_loss: 0.006030 took: 3.32s\n",
      "Epoch 4, 70% \t train_loss: 0.007729 took: 4.00s\n",
      "Epoch 4, 80% \t train_loss: 0.004436 took: 3.69s\n",
      "Epoch 4, 90% \t train_loss: 0.005134 took: 3.12s\n",
      "Training finished, took 144.17s\n",
      "Epoch 5, 10% \t train_loss: 0.005245 took: 5.25s\n",
      "Epoch 5, 20% \t train_loss: 0.004558 took: 3.21s\n",
      "Epoch 5, 30% \t train_loss: 0.003806 took: 3.08s\n",
      "Epoch 5, 40% \t train_loss: 0.003789 took: 3.11s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, 50% \t train_loss: 0.004455 took: 3.07s\n",
      "Epoch 5, 60% \t train_loss: 0.005849 took: 3.18s\n",
      "Epoch 5, 70% \t train_loss: 0.003941 took: 3.12s\n",
      "Epoch 5, 80% \t train_loss: 0.003400 took: 4.11s\n",
      "Epoch 5, 90% \t train_loss: 0.008012 took: 3.92s\n",
      "Training finished, took 179.70s\n",
      "Epoch 6, 10% \t train_loss: 0.003260 took: 4.87s\n",
      "Epoch 6, 20% \t train_loss: 0.002603 took: 3.14s\n",
      "Epoch 6, 30% \t train_loss: 0.002665 took: 3.09s\n",
      "Epoch 6, 40% \t train_loss: 0.005235 took: 3.13s\n",
      "Epoch 6, 50% \t train_loss: 0.004319 took: 3.11s\n",
      "Epoch 6, 60% \t train_loss: 0.002243 took: 3.10s\n",
      "Epoch 6, 70% \t train_loss: 0.002250 took: 3.19s\n",
      "Epoch 6, 80% \t train_loss: 0.002198 took: 3.13s\n",
      "Epoch 6, 90% \t train_loss: 0.005327 took: 3.15s\n",
      "Training finished, took 212.71s\n",
      "Epoch 7, 10% \t train_loss: 0.001882 took: 4.38s\n",
      "Epoch 7, 20% \t train_loss: 0.004054 took: 3.35s\n",
      "Epoch 7, 30% \t train_loss: 0.001929 took: 3.45s\n",
      "Epoch 7, 40% \t train_loss: 0.003027 took: 3.07s\n",
      "Epoch 7, 50% \t train_loss: 0.005544 took: 3.24s\n",
      "Epoch 7, 60% \t train_loss: 0.002838 took: 3.26s\n",
      "Epoch 7, 70% \t train_loss: 0.001677 took: 3.20s\n",
      "Epoch 7, 80% \t train_loss: 0.001424 took: 3.40s\n",
      "Epoch 7, 90% \t train_loss: 0.002866 took: 3.16s\n",
      "Training finished, took 246.48s\n",
      "Epoch 8, 10% \t train_loss: 0.002734 took: 4.26s\n",
      "Epoch 8, 20% \t train_loss: 0.002375 took: 3.07s\n",
      "Epoch 8, 30% \t train_loss: 0.001655 took: 3.08s\n",
      "Epoch 8, 40% \t train_loss: 0.002043 took: 3.12s\n",
      "Epoch 8, 50% \t train_loss: 0.001532 took: 3.09s\n",
      "Epoch 8, 60% \t train_loss: 0.004113 took: 3.12s\n",
      "Epoch 8, 70% \t train_loss: 0.001808 took: 3.13s\n",
      "Epoch 8, 80% \t train_loss: 0.001072 took: 3.18s\n",
      "Epoch 8, 90% \t train_loss: 0.001561 took: 3.70s\n",
      "Training finished, took 279.75s\n",
      "Epoch 9, 10% \t train_loss: 0.001487 took: 5.54s\n",
      "Epoch 9, 20% \t train_loss: 0.003663 took: 3.46s\n",
      "Epoch 9, 30% \t train_loss: 0.001021 took: 3.62s\n",
      "Epoch 9, 40% \t train_loss: 0.001230 took: 3.29s\n",
      "Epoch 9, 50% \t train_loss: 0.002626 took: 3.36s\n",
      "Epoch 9, 60% \t train_loss: 0.001184 took: 3.14s\n",
      "Epoch 9, 70% \t train_loss: 0.001818 took: 3.07s\n",
      "Epoch 9, 80% \t train_loss: 0.001092 took: 3.17s\n",
      "Epoch 9, 90% \t train_loss: 0.001596 took: 3.13s\n",
      "Training finished, took 314.61s\n",
      "Epoch 10, 10% \t train_loss: 0.001560 took: 4.29s\n",
      "Epoch 10, 20% \t train_loss: 0.000765 took: 3.10s\n",
      "Epoch 10, 30% \t train_loss: 0.001646 took: 3.08s\n",
      "Epoch 10, 40% \t train_loss: 0.001921 took: 3.09s\n",
      "Epoch 10, 50% \t train_loss: 0.001033 took: 3.12s\n",
      "Epoch 10, 60% \t train_loss: 0.001050 took: 3.10s\n",
      "Epoch 10, 70% \t train_loss: 0.000925 took: 3.12s\n",
      "Epoch 10, 80% \t train_loss: 0.000680 took: 3.10s\n",
      "Epoch 10, 90% \t train_loss: 0.003297 took: 3.17s\n",
      "Training finished, took 346.83s\n",
      "[[1.6574e+04 1.1000e+01]\n",
      " [1.2500e+03 1.2750e+04]]\n",
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 8\n",
      "epochs= 10\n",
      "learning_rate= 1e-06\n",
      "==============================\n",
      "Epoch 1, 10% \t train_loss: 1.904288 took: 5.17s\n",
      "Epoch 1, 20% \t train_loss: 0.503631 took: 2.99s\n",
      "Epoch 1, 30% \t train_loss: 0.337673 took: 2.99s\n",
      "Epoch 1, 40% \t train_loss: 0.261881 took: 2.98s\n",
      "Epoch 1, 50% \t train_loss: 0.194657 took: 3.09s\n",
      "Epoch 1, 60% \t train_loss: 0.161365 took: 3.06s\n",
      "Epoch 1, 70% \t train_loss: 0.127929 took: 3.06s\n",
      "Epoch 1, 80% \t train_loss: 0.113149 took: 3.06s\n",
      "Epoch 1, 90% \t train_loss: 0.094342 took: 3.02s\n",
      "Training finished, took 32.41s\n",
      "Epoch 2, 10% \t train_loss: 0.078406 took: 4.00s\n",
      "Epoch 2, 20% \t train_loss: 0.062720 took: 3.05s\n",
      "Epoch 2, 30% \t train_loss: 0.061198 took: 3.19s\n",
      "Epoch 2, 40% \t train_loss: 0.051876 took: 3.02s\n",
      "Epoch 2, 50% \t train_loss: 0.045018 took: 3.04s\n",
      "Epoch 2, 60% \t train_loss: 0.042368 took: 3.08s\n",
      "Epoch 2, 70% \t train_loss: 0.043015 took: 3.08s\n",
      "Epoch 2, 80% \t train_loss: 0.034958 took: 3.03s\n",
      "Epoch 2, 90% \t train_loss: 0.031089 took: 3.07s\n",
      "Training finished, took 63.98s\n",
      "Epoch 3, 10% \t train_loss: 0.028613 took: 4.19s\n",
      "Epoch 3, 20% \t train_loss: 0.026286 took: 3.07s\n",
      "Epoch 3, 30% \t train_loss: 0.024617 took: 3.12s\n",
      "Epoch 3, 40% \t train_loss: 0.019525 took: 3.07s\n",
      "Epoch 3, 50% \t train_loss: 0.019670 took: 3.10s\n",
      "Epoch 3, 60% \t train_loss: 0.017116 took: 3.14s\n",
      "Epoch 3, 70% \t train_loss: 0.014428 took: 4.01s\n",
      "Epoch 3, 80% \t train_loss: 0.016572 took: 3.58s\n",
      "Epoch 3, 90% \t train_loss: 0.015877 took: 3.16s\n",
      "Training finished, took 97.52s\n",
      "Epoch 4, 10% \t train_loss: 0.013175 took: 4.09s\n",
      "Epoch 4, 20% \t train_loss: 0.012220 took: 3.10s\n",
      "Epoch 4, 30% \t train_loss: 0.012866 took: 3.09s\n",
      "Epoch 4, 40% \t train_loss: 0.009322 took: 3.12s\n",
      "Epoch 4, 50% \t train_loss: 0.010101 took: 3.93s\n",
      "Epoch 4, 60% \t train_loss: 0.009429 took: 3.69s\n",
      "Epoch 4, 70% \t train_loss: 0.008637 took: 3.29s\n",
      "Epoch 4, 80% \t train_loss: 0.009904 took: 3.19s\n",
      "Epoch 4, 90% \t train_loss: 0.007263 took: 3.20s\n",
      "Training finished, took 131.37s\n",
      "Epoch 5, 10% \t train_loss: 0.008369 took: 4.22s\n",
      "Epoch 5, 20% \t train_loss: 0.005685 took: 3.18s\n",
      "Epoch 5, 30% \t train_loss: 0.006046 took: 3.18s\n",
      "Epoch 5, 40% \t train_loss: 0.005946 took: 3.23s\n",
      "Epoch 5, 50% \t train_loss: 0.006348 took: 3.26s\n",
      "Epoch 5, 60% \t train_loss: 0.004996 took: 3.47s\n",
      "Epoch 5, 70% \t train_loss: 0.007906 took: 3.70s\n",
      "Epoch 5, 80% \t train_loss: 0.005938 took: 3.68s\n",
      "Epoch 5, 90% \t train_loss: 0.005697 took: 3.15s\n",
      "Training finished, took 165.64s\n",
      "Epoch 6, 10% \t train_loss: 0.005837 took: 4.61s\n",
      "Epoch 6, 20% \t train_loss: 0.005901 took: 3.19s\n",
      "Epoch 6, 30% \t train_loss: 0.004798 took: 3.24s\n",
      "Epoch 6, 40% \t train_loss: 0.004751 took: 3.19s\n",
      "Epoch 6, 50% \t train_loss: 0.002913 took: 3.17s\n",
      "Epoch 6, 60% \t train_loss: 0.003497 took: 3.10s\n",
      "Epoch 6, 70% \t train_loss: 0.003671 took: 3.10s\n",
      "Epoch 6, 80% \t train_loss: 0.003094 took: 3.17s\n",
      "Epoch 6, 90% \t train_loss: 0.003038 took: 3.49s\n",
      "Training finished, took 199.32s\n",
      "Epoch 7, 10% \t train_loss: 0.002687 took: 4.49s\n",
      "Epoch 7, 20% \t train_loss: 0.002751 took: 3.31s\n",
      "Epoch 7, 30% \t train_loss: 0.003965 took: 3.45s\n",
      "Epoch 7, 40% \t train_loss: 0.003853 took: 3.23s\n",
      "Epoch 7, 50% \t train_loss: 0.002073 took: 3.33s\n",
      "Epoch 7, 60% \t train_loss: 0.004201 took: 3.27s\n",
      "Epoch 7, 70% \t train_loss: 0.002353 took: 3.26s\n",
      "Epoch 7, 80% \t train_loss: 0.001887 took: 3.35s\n",
      "Epoch 7, 90% \t train_loss: 0.002010 took: 3.46s\n",
      "Training finished, took 233.90s\n",
      "Epoch 8, 10% \t train_loss: 0.002418 took: 4.51s\n",
      "Epoch 8, 20% \t train_loss: 0.003273 took: 3.41s\n",
      "Epoch 8, 30% \t train_loss: 0.001751 took: 3.24s\n",
      "Epoch 8, 40% \t train_loss: 0.001271 took: 3.33s\n",
      "Epoch 8, 50% \t train_loss: 0.002264 took: 3.77s\n",
      "Epoch 8, 60% \t train_loss: 0.002005 took: 3.36s\n",
      "Epoch 8, 70% \t train_loss: 0.001957 took: 3.55s\n",
      "Epoch 8, 80% \t train_loss: 0.001471 took: 3.84s\n",
      "Epoch 8, 90% \t train_loss: 0.001490 took: 3.40s\n",
      "Training finished, took 269.46s\n",
      "Epoch 9, 10% \t train_loss: 0.001484 took: 4.14s\n",
      "Epoch 9, 20% \t train_loss: 0.001698 took: 3.11s\n",
      "Epoch 9, 30% \t train_loss: 0.001377 took: 3.13s\n",
      "Epoch 9, 40% \t train_loss: 0.001089 took: 3.12s\n",
      "Epoch 9, 50% \t train_loss: 0.001227 took: 3.08s\n",
      "Epoch 9, 60% \t train_loss: 0.002310 took: 3.07s\n",
      "Epoch 9, 70% \t train_loss: 0.000912 took: 3.15s\n",
      "Epoch 9, 80% \t train_loss: 0.001785 took: 3.15s\n",
      "Epoch 9, 90% \t train_loss: 0.001280 took: 3.17s\n",
      "Training finished, took 301.61s\n",
      "Epoch 10, 10% \t train_loss: 0.001939 took: 4.09s\n",
      "Epoch 10, 20% \t train_loss: 0.001074 took: 3.16s\n",
      "Epoch 10, 30% \t train_loss: 0.000915 took: 3.35s\n",
      "Epoch 10, 40% \t train_loss: 0.001486 took: 4.10s\n",
      "Epoch 10, 50% \t train_loss: 0.001037 took: 3.85s\n",
      "Epoch 10, 60% \t train_loss: 0.000786 took: 3.22s\n",
      "Epoch 10, 70% \t train_loss: 0.000996 took: 3.20s\n",
      "Epoch 10, 80% \t train_loss: 0.000678 took: 3.13s\n",
      "Epoch 10, 90% \t train_loss: 0.000917 took: 3.17s\n",
      "Training finished, took 336.05s\n",
      "[[2.072e+04 1.200e+01]\n",
      " [1.750e+03 1.575e+04]]\n",
      "[[2.072e+04 1.200e+01]\n",
      " [1.750e+03 1.575e+04]]\n",
      "accuracy:  0.999086626285934\n",
      "sensitivity: 0.9\n",
      "specificity: 0.9994211846420992\n",
      "precision: 0.84\n",
      "F1: 0.8689655172413793\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "k_fold = 5\n",
    "batch_size = 8\n",
    "features_og = features\n",
    "targets_og = targets\n",
    "\n",
    "train_sampler_list, test_sampler_list, train = split_train_test_kfold(features_og , targets_og, k_fold=k_fold)\n",
    "\n",
    "cm = np.zeros((2,2))\n",
    "for train_sampler, test_sampler in zip(train_sampler_list, test_sampler_list):\n",
    "    CNN = SimpleCNN()\n",
    "    val_loader = torch.utils.data.DataLoader(train, batch_size=32, sampler=train_sampler, num_workers=2)\n",
    "    trainNet(CNN, train_sampler, batch_size=batch_size, n_epochs=10, learning_rate=1e-6)# 2,5,1e-6 \n",
    "    cm += calculate_cm(test_sampler)\n",
    "    print(cm)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "fn=fn/250\n",
    "tp=tp/250\n",
    "acc = (tp+tn)/(tn+fp+fn+tp)\n",
    "sen = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "prec = tp/(tp+fp)\n",
    "F1 = 2 * (prec * sen) / (prec + sen)\n",
    "\n",
    "print(cm)\n",
    "print('accuracy: ',acc)\n",
    "print('sensitivity:', sen)\n",
    "print('specificity:', spec)\n",
    "print('precision:', prec)\n",
    "print('F1:', F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "CNN = torch.load('CNN.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "fn=fn/250\n",
    "tp=tp/250\n",
    "acc = (tp+tn)/(tn+fp+fn+tp)\n",
    "sen = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "prec = tp/(tp+fp)\n",
    "F1 = 2 * (prec * sen) / (prec + sen)\n",
    "\n",
    "print(cm)\n",
    "print('accuracy: ',acc)\n",
    "print('sensitivity:', sen)\n",
    "print('specificity:', spec)\n",
    "print('precision:', prec)\n",
    "print('F1:', F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-0fad5078900c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(np.array(y_true), np.array(y_pred))\n",
    "    \n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "cm = np.zeros((2,2))\n",
    "total=0\n",
    "correct=0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data          \n",
    "        outputs = CNN(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        for x,y in zip(predicted, labels):\n",
    "            y_true.append(int(y.numpy()))\n",
    "            y_pred.append(int(x.numpy()))\n",
    "            \n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "cm = confusion_matrix(np.array(y_true), np.array(y_pred))\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "acc = (tp+tn)/(tn+fp+fn+tp)\n",
    "sen = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "prec = tp/(tp+fp)\n",
    "F1 = 2 * (prec * sen) / (prec + sen)\n",
    "\n",
    "print(cm)\n",
    "print('accuracy: ',acc)\n",
    "print('sensitivity:', sen)\n",
    "print('specificity:', spec)\n",
    "print('precision:', prec)\n",
    "print('F1:', F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize CNN running on an actual file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = {}\n",
    "df_t['1'] = read_single_edf('chb01_03') # Figure out how to do python 2 wrapp\n",
    "width = 8\n",
    "\n",
    "feature, target = df_to_spectrogram_FT(df, sliding=True, avg=True, sliding_ft=False, width=8, stft=True)\n",
    "\n",
    "# Convert feature to tensor\n",
    "# Run it into the CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize some example of CNN labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 99110.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 99110.] (20802, 1)\n"
     ]
    }
   ],
   "source": [
    "limit = 10\n",
    "train_sampler_list, test_sampler_list, train = split_train_test_kfold(features , targets, k_fold=10)\n",
    "test_loader = get_train_loader(1, train_sampler_list[0])\n",
    "features_og = features\n",
    "targets_og = targets\n",
    "count = 0\n",
    "for i, data in enumerate(test_loader):\n",
    "    if count > limit:\n",
    "        break\n",
    "    images, labels = data\n",
    "    for x,y in zip(images,labels):\n",
    "        x = x.numpy()\n",
    "        y = y.numpy()\n",
    "        outputs = CNN(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted = predicted.numpy()[0]\n",
    "        if y>0 and y<1:\n",
    "            x=np.mean(x,axis=0)\n",
    "\n",
    "            plt.pcolormesh(np.arange(x.shape[1])*0.875,np.arange(x.shape[0]),x)\n",
    "            plt.ylabel('Frequency [Hz]')\n",
    "            plt.xlabel('Time [sec]')\n",
    "            plt.colorbar()\n",
    "            if y:\n",
    "                plt.title('Seizure Spectrogram (dB)')\n",
    "            else:\n",
    "                plt.title('Normal Spectrogram (dB)')\n",
    "            plt.show()\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced imaging (Class specific image generation)\n",
    "Cite: utkuozbulak/pytorch-cnn-visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torchvision import models\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "\n",
    "def preprocess_image(cv2im, resize_im=True):\n",
    "    \"\"\"\n",
    "        Processes image for CNNs\n",
    "\n",
    "    Args:\n",
    "        PIL_img (PIL_img): Image to process\n",
    "        resize_im (bool): Resize to 224 or not\n",
    "    returns:\n",
    "        im_as_var (Pytorch variable): Variable that contains processed float tensor\n",
    "    \"\"\"\n",
    "    # mean and std list for channels (Imagenet)\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    # Resize image\n",
    "    if resize_im:\n",
    "        cv2im = cv2.resize(cv2im, (224, 224))\n",
    "    im_as_arr = np.float32(cv2im)\n",
    "    im_as_arr = np.ascontiguousarray(im_as_arr[..., ::-1])\n",
    "    im_as_arr = im_as_arr.transpose(2, 0, 1)  # Convert array to D,W,H\n",
    "    # Normalize the channels\n",
    "    for channel, _ in enumerate(im_as_arr):\n",
    "        im_as_arr[channel] /= 255\n",
    "        im_as_arr[channel] -= mean[channel%3]#@\n",
    "        im_as_arr[channel] /= std[channel%3]#@\n",
    "    # Convert to float tensor\n",
    "    im_as_ten = torch.from_numpy(im_as_arr).float()\n",
    "    # Add one more channel to the beginning. Tensor shape = 1,3,224,224\n",
    "    im_as_ten.unsqueeze_(0)\n",
    "    # Convert to Pytorch variable\n",
    "    im_as_var = Variable(im_as_ten, requires_grad=True)\n",
    "    return im_as_var\n",
    "\n",
    "def recreate_image(im_as_var):\n",
    "    \"\"\"\n",
    "        Recreates images from a torch variable, sort of reverse preprocessing\n",
    "\n",
    "    Args:\n",
    "        im_as_var (torch variable): Image to recreate\n",
    "\n",
    "    returns:\n",
    "        recreated_im (numpy arr): Recreated image in array\n",
    "    \"\"\"\n",
    "    reverse_mean = [-0.485, -0.456, -0.406]\n",
    "    reverse_std = [1/0.229, 1/0.224, 1/0.225]\n",
    "    recreated_im = copy.copy(im_as_var.data.numpy()[0])\n",
    "    for c in range(3):\n",
    "        recreated_im[c] /= reverse_std[c]\n",
    "        recreated_im[c] -= reverse_mean[c]\n",
    "    recreated_im[recreated_im > 1] = 1\n",
    "    recreated_im[recreated_im < 0] = 0\n",
    "    recreated_im = np.round(recreated_im * 255)\n",
    "\n",
    "    recreated_im = np.uint8(recreated_im).transpose(1, 2, 0)\n",
    "    # Convert RBG to GBR\n",
    "    recreated_im = recreated_im[..., ::-1]\n",
    "    return recreated_im\n",
    "\n",
    "class ClassSpecificImageGeneration():\n",
    "    \"\"\"\n",
    "        Produces an image that maximizes a certain class with gradient ascent\n",
    "    \"\"\"\n",
    "    def __init__(self, model, target_class):\n",
    "        self.mean = [-0.485, -0.456, -0.406]\n",
    "        self.std = [1/0.229, 1/0.224, 1/0.225]\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.target_class = target_class\n",
    "        # Generate a random image\n",
    "        self.created_image = np.uint8(np.random.uniform(0, 255, (8, 128, 23))) #@\n",
    "        print(self.created_image.shape)\n",
    "        # Create the folder to export images if not exists\n",
    "        if not os.path.exists('../generated'):\n",
    "            os.makedirs('../generated')\n",
    "\n",
    "    def generate(self):\n",
    "        initial_learning_rate = 6\n",
    "        for i in range(1, 901):\n",
    "            # Process image and return variable\n",
    "            self.processed_image = preprocess_image(self.created_image)\n",
    "            # Define optimizer for the image\n",
    "            optimizer = SGD([self.processed_image], lr=initial_learning_rate)\n",
    "            # Forward\n",
    "            output = self.model(self.processed_image)\n",
    "            # Target specific class\n",
    "            class_loss = -output[0, self.target_class]\n",
    "            #print('Iteration:', str(i), 'Loss', \"{0:.2f}\".format(class_loss.data.numpy()[0]))\n",
    "            # Zero grads\n",
    "            self.model.zero_grad()\n",
    "            # Backward\n",
    "            class_loss.backward()\n",
    "            # Update image\n",
    "            optimizer.step()\n",
    "            # Recreate image\n",
    "            self.created_image = recreate_image(self.processed_image)\n",
    "            # Save image\n",
    "            if i%100 == 0:\n",
    "                cv2.imwrite('../generated/c_specific_iteration_'+str(i)+'.jpg', self.created_image[:,:,0:3])\n",
    "        return self.processed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 128, 23)\n"
     ]
    }
   ],
   "source": [
    "target_class = 1  # Flamingo\n",
    "pretrained_model = CNN\n",
    "csig = ClassSpecificImageGeneration(pretrained_model, target_class)\n",
    "img_s = csig.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 128, 23)\n"
     ]
    }
   ],
   "source": [
    "target_class = 0  # Flamingo\n",
    "pretrained_model = CNN\n",
    "csig = ClassSpecificImageGeneration(pretrained_model, target_class)\n",
    "img_ns = csig.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "delta_img = img_s.detach().numpy()[0]-img_ns.detach().numpy()[0]\n",
    "delta_img = np.mean(delta_img, axis = 0)\n",
    "plt.imshow(delta_img.T, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import ReLU\n",
    "\n",
    "class GuidedBackprop():\n",
    "    \"\"\"\n",
    "       Produces gradients generated with guided back propagation from the given image\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.gradients = None\n",
    "        # Put model in evaluation mode\n",
    "        self.model.eval()\n",
    "        self.update_relus()\n",
    "        self.hook_layers()\n",
    "\n",
    "    def hook_layers(self):\n",
    "        def hook_function(module, grad_in, grad_out):\n",
    "            self.gradients = grad_in[0]\n",
    "\n",
    "        # Register hook to the first layer\n",
    "        first_layer = list(self.model.features._modules.items())[0][1]\n",
    "        first_layer.register_backward_hook(hook_function)\n",
    "\n",
    "    def update_relus(self):\n",
    "        \"\"\"\n",
    "            Updates relu activation functions so that it only returns positive gradients\n",
    "        \"\"\"\n",
    "        def relu_hook_function(module, grad_in, grad_out):\n",
    "            \"\"\"\n",
    "            If there is a negative gradient, changes it to zero\n",
    "            \"\"\"\n",
    "            if isinstance(module, ReLU):\n",
    "                return (torch.clamp(grad_in[0], min=0.0),)\n",
    "        # Loop through layers, hook up ReLUs with relu_hook_function\n",
    "        for pos, module in self.model.features._modules.items():\n",
    "            if isinstance(module, ReLU):\n",
    "                module.register_backward_hook(relu_hook_function)\n",
    "\n",
    "    def generate_gradients(self, input_image, target_class):\n",
    "        # Forward pass\n",
    "        model_output = self.model(input_image)\n",
    "        # Zero gradients\n",
    "        self.model.zero_grad()\n",
    "        # Target for backprop\n",
    "        one_hot_output = torch.FloatTensor(1, model_output.size()[-1]).zero_()\n",
    "        one_hot_output[0][target_class] = 1\n",
    "        # Backward pass\n",
    "        model_output.backward(gradient=one_hot_output)\n",
    "        # Convert Pytorch variable to numpy array\n",
    "        # [0] to get rid of the first channel (1,3,224,224)\n",
    "        gradients_as_arr = self.gradients.data.numpy()[0]\n",
    "        return gradients_as_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "/home/travis/miniconda/conda-bld/conda_1486587069159/work/opencv-3.1.0/modules/imgproc/src/imgwarp.cpp:3229: error: (-215) ssize.area() > 0 in function resize\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-e892c6c4c26d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtarget_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m  \u001b[0;31m# Snake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprep_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name_to_export\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_model\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m        \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Guided backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-114-041926e4ac80>\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(example_index)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0moriginal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;31m# Process image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mprep_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;31m# Define model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mpretrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malexnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-114-041926e4ac80>\u001b[0m in \u001b[0;36mpreprocess_image\u001b[0;34m(cv2im, resize_im)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# Resize image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresize_im\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mcv2im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0mim_as_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mim_as_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_as_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /home/travis/miniconda/conda-bld/conda_1486587069159/work/opencv-3.1.0/modules/imgproc/src/imgwarp.cpp:3229: error: (-215) ssize.area() > 0 in function resize\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    target_example = 0  # Snake\n",
    "    (original_image, prep_img, target_class, file_name_to_export, pretrained_model) =\\\n",
    "        get_params(target_example)\n",
    "    \n",
    "    original_image = \n",
    "    pretrained_model = CNN\n",
    "    # Guided backprop\n",
    "    GBP = GuidedBackprop(pretrained_model)\n",
    "    # Get gradients\n",
    "    guided_grads = GBP.generate_gradients(prep_img, target_class)\n",
    "    # Save colored gradients\n",
    "    save_gradient_images(guided_grads, file_name_to_export + '_Guided_BP_color')\n",
    "    # Convert to grayscale\n",
    "    grayscale_guided_grads = convert_to_grayscale(guided_grads)\n",
    "    # Save grayscale gradients\n",
    "    save_gradient_images(grayscale_guided_grads, file_name_to_export + '_Guided_BP_gray')\n",
    "    # Positive and negative saliency maps\n",
    "    pos_sal, neg_sal = get_positive_negative_saliency(guided_grads)\n",
    "    save_gradient_images(pos_sal, file_name_to_export + '_pos_sal')\n",
    "    save_gradient_images(neg_sal, file_name_to_export + '_neg_sal')\n",
    "    print('Guided backprop completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Thu Oct 21 11:09:09 2017\n",
    "\n",
    "@author: Utku Ozbulak - github.com/utkuozbulak\n",
    "\"\"\"\n",
    "import os\n",
    "import copy\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "def convert_to_grayscale(cv2im):\n",
    "    \"\"\"\n",
    "        Converts 3d image to grayscale\n",
    "\n",
    "    Args:\n",
    "        cv2im (numpy arr): RGB image with shape (D,W,H)\n",
    "\n",
    "    returns:\n",
    "        grayscale_im (numpy_arr): Grayscale image with shape (1,W,D)\n",
    "    \"\"\"\n",
    "    grayscale_im = np.sum(np.abs(cv2im), axis=0)\n",
    "    im_max = np.percentile(grayscale_im, 99)\n",
    "    im_min = np.min(grayscale_im)\n",
    "    grayscale_im = (np.clip((grayscale_im - im_min) / (im_max - im_min), 0, 1))\n",
    "    grayscale_im = np.expand_dims(grayscale_im, axis=0)\n",
    "    return grayscale_im\n",
    "\n",
    "\n",
    "def save_gradient_images(gradient, file_name):\n",
    "    \"\"\"\n",
    "        Exports the original gradient image\n",
    "\n",
    "    Args:\n",
    "        gradient (np arr): Numpy array of the gradient with shape (3, 224, 224)\n",
    "        file_name (str): File name to be exported\n",
    "    \"\"\"\n",
    "    if not os.path.exists('../results'):\n",
    "        os.makedirs('../results')\n",
    "    gradient = gradient - gradient.min()\n",
    "    gradient /= gradient.max()\n",
    "    gradient = np.uint8(gradient * 255).transpose(1, 2, 0)\n",
    "    path_to_file = os.path.join('../results', file_name + '.jpg')\n",
    "    # Convert RBG to GBR\n",
    "    gradient = gradient[..., ::-1]\n",
    "    cv2.imwrite(path_to_file, gradient)\n",
    "\n",
    "\n",
    "def save_class_activation_on_image(org_img, activation_map, file_name):\n",
    "    \"\"\"\n",
    "        Saves cam activation map and activation map on the original image\n",
    "\n",
    "    Args:\n",
    "        org_img (PIL img): Original image\n",
    "        activation_map (numpy arr): activation map (grayscale) 0-255\n",
    "        file_name (str): File name of the exported image\n",
    "    \"\"\"\n",
    "    if not os.path.exists('../results'):\n",
    "        os.makedirs('../results')\n",
    "    # Grayscale activation map\n",
    "    path_to_file = os.path.join('../results', file_name+'_Cam_Grayscale.jpg')\n",
    "    cv2.imwrite(path_to_file, activation_map)\n",
    "    # Heatmap of activation map\n",
    "    activation_heatmap = cv2.applyColorMap(activation_map, cv2.COLORMAP_HSV)\n",
    "    path_to_file = os.path.join('../results', file_name+'_Cam_Heatmap.jpg')\n",
    "    cv2.imwrite(path_to_file, activation_heatmap)\n",
    "    # Heatmap on picture\n",
    "    org_img = cv2.resize(org_img, (224, 224))\n",
    "    img_with_heatmap = np.float32(activation_heatmap) + np.float32(org_img)\n",
    "    img_with_heatmap = img_with_heatmap / np.max(img_with_heatmap)\n",
    "    path_to_file = os.path.join('../results', file_name+'_Cam_On_Image.jpg')\n",
    "    cv2.imwrite(path_to_file, np.uint8(255 * img_with_heatmap))\n",
    "\n",
    "\n",
    "def preprocess_image(cv2im, resize_im=True):\n",
    "    \"\"\"\n",
    "        Processes image for CNNs\n",
    "\n",
    "    Args:\n",
    "        PIL_img (PIL_img): Image to process\n",
    "        resize_im (bool): Resize to 224 or not\n",
    "    returns:\n",
    "        im_as_var (Pytorch variable): Variable that contains processed float tensor\n",
    "    \"\"\"\n",
    "    # mean and std list for channels (Imagenet)\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    # Resize image\n",
    "    if resize_im:\n",
    "        cv2im = cv2.resize(cv2im, (224, 224))\n",
    "    im_as_arr = np.float32(cv2im)\n",
    "    im_as_arr = np.ascontiguousarray(im_as_arr[..., ::-1])\n",
    "    im_as_arr = im_as_arr.transpose(2, 0, 1)  # Convert array to D,W,H\n",
    "    # Normalize the channels\n",
    "    for channel, _ in enumerate(im_as_arr):\n",
    "        im_as_arr[channel] /= 255\n",
    "        im_as_arr[channel] -= mean[channel]\n",
    "        im_as_arr[channel] /= std[channel]\n",
    "    # Convert to float tensor\n",
    "    im_as_ten = torch.from_numpy(im_as_arr).float()\n",
    "    # Add one more channel to the beginning. Tensor shape = 1,3,224,224\n",
    "    im_as_ten.unsqueeze_(0)\n",
    "    # Convert to Pytorch variable\n",
    "    im_as_var = Variable(im_as_ten, requires_grad=True)\n",
    "    return im_as_var\n",
    "\n",
    "\n",
    "def recreate_image(im_as_var):\n",
    "    \"\"\"\n",
    "        Recreates images from a torch variable, sort of reverse preprocessing\n",
    "\n",
    "    Args:\n",
    "        im_as_var (torch variable): Image to recreate\n",
    "\n",
    "    returns:\n",
    "        recreated_im (numpy arr): Recreated image in array\n",
    "    \"\"\"\n",
    "    reverse_mean = [-0.485, -0.456, -0.406]\n",
    "    reverse_std = [1/0.229, 1/0.224, 1/0.225]\n",
    "    recreated_im = copy.copy(im_as_var.data.numpy()[0])\n",
    "    for c in range(3):\n",
    "        recreated_im[c] /= reverse_std[c]\n",
    "        recreated_im[c] -= reverse_mean[c]\n",
    "    recreated_im[recreated_im > 1] = 1\n",
    "    recreated_im[recreated_im < 0] = 0\n",
    "    recreated_im = np.round(recreated_im * 255)\n",
    "\n",
    "    recreated_im = np.uint8(recreated_im).transpose(1, 2, 0)\n",
    "    # Convert RBG to GBR\n",
    "    recreated_im = recreated_im[..., ::-1]\n",
    "    return recreated_im\n",
    "\n",
    "\n",
    "def get_positive_negative_saliency(gradient):\n",
    "    \"\"\"\n",
    "        Generates positive and negative saliency maps based on the gradient\n",
    "    Args:\n",
    "        gradient (numpy arr): Gradient of the operation to visualize\n",
    "\n",
    "    returns:\n",
    "        pos_saliency ( )\n",
    "    \"\"\"\n",
    "    pos_saliency = (np.maximum(0, gradient) / gradient.max())\n",
    "    neg_saliency = (np.maximum(0, -gradient) / -gradient.min())\n",
    "    return pos_saliency, neg_saliency\n",
    "\n",
    "\n",
    "def get_params(example_index):\n",
    "    \"\"\"\n",
    "        Gets used variables for almost all visualizations, like the image, model etc.\n",
    "\n",
    "    Args:\n",
    "        example_index (int): Image id to use from examples\n",
    "\n",
    "    returns:\n",
    "        original_image (numpy arr): Original image read from the file\n",
    "        prep_img (numpy_arr): Processed image\n",
    "        target_class (int): Target class for the image\n",
    "        file_name_to_export (string): File name to export the visualizations\n",
    "        pretrained_model(Pytorch model): Model to use for the operations\n",
    "    \"\"\"\n",
    "    # Pick one of the examples\n",
    "    example_list = [['../input_images/snake.jpg', 56],\n",
    "                    ['../input_images/cat_dog.png', 243],\n",
    "                    ['../input_images/spider.png', 72]]\n",
    "    selected_example = example_index\n",
    "    img_path = example_list[selected_example][0]\n",
    "    target_class = example_list[selected_example][1]\n",
    "    file_name_to_export = img_path[img_path.rfind('/')+1:img_path.rfind('.')]\n",
    "    # Read image\n",
    "    original_image = cv2.imread(img_path, 1)\n",
    "    # Process image\n",
    "    prep_img = preprocess_image(original_image)\n",
    "    # Define model\n",
    "    pretrained_model = models.alexnet(pretrained=True)\n",
    "    return (original_image,\n",
    "            prep_img,\n",
    "            target_class,\n",
    "            file_name_to_export,\n",
    "            pretrained_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
